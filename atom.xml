<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chenci&#39;blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-04-08T11:01:08.871Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Chenci</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>scrapy框架学习</title>
    <link href="http://example.com/2022/04/08/scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://example.com/2022/04/08/scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/</id>
    <published>2022-04-08T10:57:11.000Z</published>
    <updated>2022-04-08T11:01:08.871Z</updated>
    
    <content type="html"><![CDATA[<p>创建项目</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject tutorial</span><br></pre></td></tr></table></figure><p>创建任务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider first www.baidu.com</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;创建项目&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;p</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>ubuntu下hadoop集群搭建</title>
    <link href="http://example.com/2022/03/01/ubuntu%E4%B8%8Bhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/03/01/ubuntu%E4%B8%8Bhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2022-03-01T14:02:18.000Z</published>
    <updated>2022-04-08T08:28:31.269Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-配置ip-三个节点"><a href="#一-配置ip-三个节点" class="headerlink" title="一.配置ip(三个节点)"></a>一.配置ip(三个节点)</h3><p>自ubuntu17之后多了一种配置方式更加高效,也就是netplan</p><p>1.1编辑配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:/etc/netplan# gedit /etc/netplan/01-network-manager-all.yaml</span><br></pre></td></tr></table></figure><p>配置内容如下,<code>注意缩进</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  renderer: NetworkManager</span><br><span class="line">  ethernets:</span><br><span class="line">     ens33:</span><br><span class="line">       dhcp4:  no</span><br><span class="line">       dhcp6:  no</span><br><span class="line">       addresses:  [192.168.10.101/24]</span><br><span class="line">       gateway4:  192.168.10.1</span><br><span class="line">       nameservers:</span><br><span class="line">         addresses: [8.8.8.8,192.168.10.1]</span><br></pre></td></tr></table></figure><p>1.2使配置生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:/etc/netplan# netplan apply</span><br></pre></td></tr></table></figure><p>如果没有报错则配置成功</p><h3 id="配置主机名和主机名映射-三个节点"><a href="#配置主机名和主机名映射-三个节点" class="headerlink" title="配置主机名和主机名映射(三个节点)"></a>配置主机名和主机名映射(三个节点)</h3><p>1.1配置主机名并查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">重启后生效</span><br><span class="line">root@master:/etc/netplan# hostnamectl set-hostname master</span><br><span class="line">root@master:/etc/netplan# hostname</span><br></pre></td></tr></table></figure><p>1.2配置主机名映射</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:/etc/netplan# gedit /etc/hosts</span><br></pre></td></tr></table></figure><p>添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.10.101 master</span><br><span class="line">192.168.10.102 slave1</span><br><span class="line">192.168.10.103 slave2</span><br></pre></td></tr></table></figure><p>1.3ping测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">有以下回显证明配置成功</span><br><span class="line">root@master:/etc/netplan# ping slave2</span><br><span class="line">PING slave2 (192.168.10.103) 56(84) bytes of data.</span><br><span class="line">64 bytes from slave2 (192.168.10.103): icmp_seq=1 ttl=64 time=0.891 ms</span><br><span class="line">64 bytes from slave2 (192.168.10.103): icmp_seq=2 ttl=64 time=0.369 ms</span><br><span class="line">64 bytes from slave2 (192.168.10.103): icmp_seq=3 ttl=64 time=0.455 ms</span><br></pre></td></tr></table></figure><p>1.4将hosts文件分发给子节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:/etc/netplan# scp /etc/hosts root@slave1:/etc/</span><br><span class="line">输入yes再输入密码</span><br></pre></td></tr></table></figure><h3 id="三-配置ssh免密登录-三个节点"><a href="#三-配置ssh免密登录-三个节点" class="headerlink" title="三.配置ssh免密登录(三个节点)"></a>三.配置ssh免密登录(三个节点)</h3><p>因为Ubuntu并不自带ssh服务所以要安装ssh并配置允许root远程登录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">下载</span><br><span class="line">sudo apt-get install openssh-server</span><br><span class="line">启动</span><br><span class="line">sudo service ssh start</span><br><span class="line">配置</span><br><span class="line">sudo vim /etc/ssh/sshd_config</span><br><span class="line">添加一条</span><br><span class="line">PermitRootLogin yes</span><br></pre></td></tr></table></figure><p>1.生成密钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~# ssh-keygen -t rsa</span><br><span class="line">一直回车</span><br></pre></td></tr></table></figure><p>2.将密钥写入authorized.keys文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@master:~# cd .ssh/</span><br><span class="line">root@master:~/.ssh# cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3.在另外两个子节点执行以上操作,并将authorized.keys的内容复制进master主机的authorized.keys文件末尾,成功后如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/.ssh# cat authorized.keys </span><br><span class="line">ssh-dss AAAAB3NzaC1kc3MAAACBAIzJrAXCuK15C+mq3TkdFFJUJiuY9rMo6L6LoU+naCEKJNKfRDXXAXDcRC2TJK5JqnWHuexfOusYZS/kpRU4JO1S4VGzq446r5QM19c7xH3TkE2A2W2Z9AA/7G+UHzqyHWQ6gDRIsqqsF6MlJUtOO7x3XtNUVYrtIzvUeqTbXrbJAAAAFQCsjTDCWxn2PU5WobBN/xYTxS9vdwAAAIBcM2X2tlkwnmpNcm3a1Cf4addU395AfJfhOwdqacHSCdiaNSlx7kVkd8T1Hk+gvF0KzP4KbjqiGWsGEiaYdlU4Ujrei+VplG8moa4GcCA/wUzpAioeULCP+0+870/+NwFUt7XKhYk9llUrh56LWev5c5YC3aNQ0GzElBxjUj8v4gAAAIBpUWTTkmdeL7ploxSCR56Js0pMFJiGvKP6tMkc3UL5Vwl5RDqJt+eFd31SDVJVVEK3vX06wujOlDbHwdIfpE48y2dN7nRn5bK3ccg1yo7Cq7Vtj4TlODYTkPYxXaR2e8dqW9bg8anXvaCI7AylRwPYNnQIgcjPeC4qJsRuMq4Mag== root@master</span><br><span class="line">ssh-dss AAAAB3NzaC1kc3MAAACBAMxF+Q5Kg1DluBqo0vZKPlE0uB2+1cDTn/f2xN0ug5mYa3WDpC36p8P2iQ4IrZEp7BqFEiQSstbZd+Im4qpaBRlHnWZhym5oOqY2a4JVsrAtyTObYFM/+/eEtQ/0Bl6UxeRKkWWPuZwbtYREEnbJ2VwLzvIJEBDVkZcccY58TO8LAAAAFQC41GJzzSEGbZLDCu2Fgzo3iml/ZQAAAIBpWqD1HHm5gTyp/6h+hCEDMP1cOOl11e+f4ZO+vhpYm+AXqpEbmMr2UTSBlc93PdJRxiIAIKidWmcLaaSuLDYWoeDDcFGCclz9bCoXZmeOVoAe096jyNFPZGorb7mqnif3oRI5hkqsmph2AX/9n90taaLUF5VrgJVEAOPLkjZ+IAAAAIEAsc7MCMYn7phJIACMypSeeWkmjUisRxVEp6u6WWHQ3GsImNkjR7UmFVxnpYOikexsPsbhlXahTIas7SQiPNRsgxi2nDBwauEvkRHQID5LbjFiIp97xbrSg8T0H23MXlBbI/MycFcyuxBIUOL5zSrz8CcUG6uQtLDMGAEVkCHORCU= root@slave1</span><br><span class="line">ssh-dss AAAAB3NzaC1kc3MAAACBANwhno/+fLpWNOg1NOrBQ+qs7XWLZeu+Xxl/g5eJOD9+qaQKTWLOYfgyez38cpqjZ9r39tKRR5HQ7RVlM0tJicGgz+jCdtRoQKs6W5mc3SCmW+u+ILMxxTqdUHUKsNq4NauoVcSduq4ot8HKpi2GBGWE1MCNgCaSnH6TB8tvl49lAAAAFQCnfx5p+/KbSsrlSFo9BYuAhEuI7QAAAIA4lsxJjI3bn/FQsSjzcjIyRLiut432/i/QngE7Y9UwQGXKY9x8z7EksXDpdswo2M2cBSZsrelSnoiUYHjusSfMTptzdT8WUWCutCd7Kn1zU4fPJCM4gTNuECjHaWU/t7BVJXHGkB6eWErcHxnm6iILVLCFf9wm8oPMjRJmLLQGhQAAAIEAkA+YrcoTQfuZbS8ACHN3zkvg1/gAmx26owiZsMrSaV1rbrJ6WgWCX+Ux9CHIkKK4MZrJrXVQpoal5/PEPw0OCZepCHOGVLNcrhyhKNov1EzSC664Mb0l+9bHh+zXjv/X0yrMB1bY16eNMBCnx0YsJ5vuXZtZRg9ms6dEh5eA/LY= root@slave2</span><br></pre></td></tr></table></figure><p>4.分发给另外两台子节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/.ssh# scp ./authorized.keys root@slave1:/root/.ssh/</span><br><span class="line">root@master:~/.ssh# scp ./authorized.keys root@slave2:/root/.ssh/</span><br></pre></td></tr></table></figure><p>5.测试免密登录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh master</span><br><span class="line">ssh slave1</span><br><span class="line">ssh slave2</span><br></pre></td></tr></table></figure><h3 id="四-安装jdk"><a href="#四-安装jdk" class="headerlink" title="四.安装jdk"></a>四.安装jdk</h3><p>1.解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/jdk/jdk1.8.0_11# tar -zxvf jdk-8u11-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><p>2.分发给其余子节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp -r /root/software/jdk/jdk1.8.0_11/ root@slave1:/root/software/jdk/</span><br><span class="line">cp -r /root/software/jdk/jdk1.8.0_11/ root@slave2:/root/software/jdk/</span><br></pre></td></tr></table></figure><p>3.配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/jdk/jdk1.8.0_11# gedit /root/.bashrc </span><br></pre></td></tr></table></figure><p>配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/root/software/jdk/jdk1.8.0_11</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><p>分发给其他节点,也可以直接配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/jdk/jdk1.8.0_11# scp -r /root/.bashrc root@slave1:/root/</span><br><span class="line">root@master:~/software/jdk/jdk1.8.0_11# scp -r /root/.bashrc root@slave2:/root/</span><br></pre></td></tr></table></figure><p>4.刷新环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/jdk/jdk1.8.0_11# source /root/.bashrc </span><br></pre></td></tr></table></figure><p>5.测试<br>如下回显则表示成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/jdk/jdk1.8.0_11# java -version</span><br><span class="line">java version &quot;1.8.0_11&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_11-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.11-b03, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="五-安装hadoop"><a href="#五-安装hadoop" class="headerlink" title="五.安装hadoop"></a>五.安装hadoop</h3><p>1.解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop# tar -zxvf hadoop-2.7.3.tar.gz</span><br></pre></td></tr></table></figure><p>2.配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop# gedit /root/.bashrc </span><br></pre></td></tr></table></figure><p>配置如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/root/software/hadoop/hadoop-2.7.3</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP/sbin:$PATH</span><br></pre></td></tr></table></figure><p>分发给子节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop# scp -r /root/.bashrc root@slave1:/root/</span><br><span class="line">root@master:~/software/hadoop# scp -r /root/.bashrc root@slave2:/root/</span><br></pre></td></tr></table></figure><p>刷新环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop# source /root/.bashrc </span><br></pre></td></tr></table></figure><p>3.创建hadoopdata目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3# mkdir hadoopdata</span><br></pre></td></tr></table></figure><p>4.配置hadoop-env.sh文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# cd etc/hadoop/</span><br><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit hadoop-env.sh </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">找到</span><br><span class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;</span><br><span class="line">修改为</span><br><span class="line">export JAVA_HOME=/root/software/jdk/jdk1.8.0_11</span><br></pre></td></tr></table></figure><p>5.配置yarn-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit yarn-env.sh </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">找到</span><br><span class="line"><span class="meta">#</span><span class="language-bash"><span class="built_in">export</span> JAVA_HOME=/home/y/libexec/jdk1.6.0/</span></span><br><span class="line">修改为</span><br><span class="line">export JAVA_HOME=/root/software/jdk/jdk1.8.0_11</span><br></pre></td></tr></table></figure><p>6.配置核心组件core-site.xml </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit core-site.xml </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/root/software/hadoop/hadoop-2.7.3/hadoopdata&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>7.配置配置文件系统hdfs-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit hdfs-site.xml </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.rpc-address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;master:50071&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>8.配置文件系统yarn-site.xm</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit yarn-site.xm</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:18040&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;property&gt;                &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:18030&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:18025&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;property&gt;                &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:18141&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;property&gt;                &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;master:18088&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>9.配置计算框架mapred-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# cp mapred-site.xml.template mapred-site.xml</span><br><span class="line"></span><br><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit mapred-site.xml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>10.配置slaves文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# gedit slaves </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><p>11.分发给子节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# scp -r /root/software/hadoop/hadoop-2.7.3/ root@slave2:/root/software/hadoop/</span><br></pre></td></tr></table></figure><p>12.格式化namanode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/etc/hadoop# hdfs namenode -format</span><br></pre></td></tr></table></figure><p>13.启动hadoop</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">进入sbin目录下执行</span><br><span class="line"></span><br><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/sbin# ./start-all.sh </span><br><span class="line"></span><br><span class="line">执行命令后，提示出入yes/no时，输入yes。</span><br></pre></td></tr></table></figure><p>14.测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/sbin# jps</span><br></pre></td></tr></table></figure><p>有以下进程表示搭建成功!</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hadoop/hadoop-2.7.3/sbin# jps</span><br><span class="line">4848 SecondaryNameNode</span><br><span class="line">4999 ResourceManager</span><br><span class="line">4489 NameNode</span><br><span class="line">4650 DataNode</span><br><span class="line">5423 Jps</span><br><span class="line">5135 NodeManager</span><br></pre></td></tr></table></figure><p>15.web端查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在Master上启动Firefox浏览器，在浏览器地址栏中输入输入http://master:50070/,有如下回显表示成功</span><br></pre></td></tr></table></figure><p><img src="/2022/03/01/ubuntu%E4%B8%8Bhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/QQ20220301-220428.png" alt="1"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在Master上启动Firefox浏览器，在浏览器地址栏中输入输入http://master:18088/，检查 Yarn是否正常，页面如下图所示。</span><br></pre></td></tr></table></figure><p><img src="/2022/03/01/ubuntu%E4%B8%8Bhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/QQ20220301-220440.png" alt="2"></p><h3 id="六-flume安装与配置"><a href="#六-flume安装与配置" class="headerlink" title="六.flume安装与配置"></a>六.flume安装与配置</h3><p>1.解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-flume-1.7.0-bin.tar.gz </span><br></pre></td></tr></table></figure><p>2.配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#FLUME_HOME</span></span><br><span class="line"><span class="built_in">export</span> FLUME_HOME=/root/software/flume-1.7.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$FLUME_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>3.复制配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> flume-env.sh.template flume-env.sh</span><br></pre></td></tr></table></figure><p>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export JAVA_HOME=/usr/lib/jvm/java-6-sun</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/root/software/jdk1.8.0_11</span><br></pre></td></tr></table></figure><p>4.配置配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">source: 数据的入口,规定了数据收集的入口规范</span><br><span class="line">channel: 管道,存储数据用的</span><br><span class="line">skin: 数据的出口,规定了数据收集的出口规范</span><br><span class="line">agent: 一个任务,包含了source,channel,skin</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> flume-conf.properties.template flume-conf.properties</span><br></pre></td></tr></table></figure><p>修改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>5.启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flume-ng agent --conf conf --conf-file conf/flume-conf.properties --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p>6.nc测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc localhost 44444</span><br></pre></td></tr></table></figure><p>7.案例一<br>监听文件内容变动，将新增加的内容输出到控制台。<br>新建配置文件 exec-memory-logger.properties,其内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources,sinks,channels</span></span><br><span class="line">a1.sources = s1  </span><br><span class="line">a1.sinks = k1  </span><br><span class="line">a1.channels = c1  </span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置sources属性</span></span><br><span class="line">a1.sources.s1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.s1.command = <span class="built_in">tail</span> -F /tmp/log.txt</span><br><span class="line">a1.sources.s1.bash = /bin/bash -c</span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources与channels进行绑定</span></span><br><span class="line">a1.sources.s1.channels = c1</span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置sink </span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks与channels进行绑定  </span></span><br><span class="line">a1.sinks.k1.channel = c1  </span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line">a1.channels.c1.type = memory</span><br></pre></td></tr></table></figure><p>8.案例二<br>监听指定端口,将这个向这个端口写入的数据输出到控制台</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = 192.168.32.130</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transctionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind the source and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>9.案例三<br>监听指定目录，将目录下新增加的文件存储到 HDFS。<br>新建配置文件spooling-memory-hdfs.properties</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources,sinks,channels</span></span><br><span class="line">a1.sources = s1  </span><br><span class="line">a1.sinks = k1  </span><br><span class="line">a1.channels = c1  </span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置sources属性</span></span><br><span class="line">a1.sources.s1.type =spooldir  </span><br><span class="line">a1.sources.s1.spoolDir =/tmp/logs</span><br><span class="line">a1.sources.s1.basenameHeader = <span class="literal">true</span></span><br><span class="line">a1.sources.s1.basenameHeaderKey = fileName </span><br><span class="line"><span class="comment">#将sources与channels进行绑定  </span></span><br><span class="line">a1.sources.s1.channels =c1 </span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置sink </span></span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /flume/events/%y-%m-%d/%H/</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = %&#123;fileName&#125;</span><br><span class="line"><span class="comment">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span></span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream  </span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = <span class="literal">true</span></span><br><span class="line"><span class="comment">#将sinks与channels进行绑定  </span></span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">   </span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line">a1.channels.c1.type = memory</span><br></pre></td></tr></table></figure><p>10.案例四<br>将本服务器收集到的数据发送到另外一台服务器。<br>新建配置 netcat-memory-avro.properties，监听文件内容变化，然后将新的文件内容通过 avro sink 发送到 hadoop001 这台服务器的 8888 端口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources,sinks,channels</span></span><br><span class="line">a1.sources = s1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sources属性</span></span><br><span class="line">a1.sources.s1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.s1.command = <span class="built_in">tail</span> -F /tmp/log.txt</span><br><span class="line">a1.sources.s1.bash = /bin/bash -c</span><br><span class="line">a1.sources.s1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop001</span><br><span class="line">a1.sinks.k1.port = 8888</span><br><span class="line">a1.sinks.k1.batch-size = 1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>配置日志聚合Flume<br>使用 avro source 监听 hadoop001 服务器的 8888 端口，将获取到内容输出到控制台</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent的sources,sinks,channels</span></span><br><span class="line">a2.sources = s2</span><br><span class="line">a2.sinks = k2</span><br><span class="line">a2.channels = c2</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sources属性</span></span><br><span class="line">a2.sources.s2.type = avro</span><br><span class="line">a2.sources.s2.bind = hadoop001</span><br><span class="line">a2.sources.s2.port = 8888</span><br><span class="line"></span><br><span class="line"><span class="comment">#将sources与channels进行绑定</span></span><br><span class="line">a2.sources.s2.channels = c2</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置sink</span></span><br><span class="line">a2.sinks.k2.type = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#将sinks与channels进行绑定</span></span><br><span class="line">a2.sinks.k2.channel = c2</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置channel类型</span></span><br><span class="line">a2.channels.c2.type = memory</span><br><span class="line">a2.channels.c2.capacity = 1000</span><br><span class="line">a2.channels.c2.transactionCapacity = 100</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里建议先启动a2，原因是 avro.source 会先与端口进行绑定，这样 avro sink 连接时才不会报无法连接的异常。但是即使不按顺序启动也是没关系的，sink 会一直重试，直至建立好连接。</p><h3 id="七-Zookeeper安装配置"><a href="#七-Zookeeper安装配置" class="headerlink" title="七.Zookeeper安装配置"></a>七.Zookeeper安装配置</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ZOOKEEPER_HOME</span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/root/software/zookeeper-3.4.5-cdh5.6.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.新建一个目录用来存放数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /root/software/zookeeper-3.4.5-cdh5.6.0/zk_data</span><br></pre></td></tr></table></figure><p>3.编辑配置文件<br>复制一份配置文件,并替换内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/root/software/zookeeper-3.4.5-cdh5.6.0/zk_data</span><br></pre></td></tr></table></figure><p>4.启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="八-kafka安装配置与使用"><a href="#八-kafka安装配置与使用" class="headerlink" title="八.kafka安装配置与使用"></a>八.kafka安装配置与使用</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#KAFKA_HOME</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_HOME=/root/software/kafka_2.11-2.0.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$KAFKA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.创建日志文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /root/software/kafka_2.11-2.0.0/kafka-logs</span><br></pre></td></tr></table></figure><p>3.config文件夹中修改配置文件以下几项</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gedit server.properties </span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log.dirs=/root/software/kafka_2.11-2.0.0/kafka-logs</span><br><span class="line"></span><br><span class="line">listeners=PLAINTEXT://localhost:9092</span><br></pre></td></tr></table></figure><p>4.启动kafka<br>启动kafka之前要先启动zookeeper</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh ./config/server.properties</span><br></pre></td></tr></table></figure><p>5.创建topic主题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper localhost: 2181/kafka --create --topic topic-demo --replication-factor 1 --partitions 1</span><br></pre></td></tr></table></figure><p>6.查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure><p>7.生产消息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo</span><br></pre></td></tr></table></figure><p>8.消费消息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo</span><br><span class="line">--beginning 可选参数,代表从头消费</span><br></pre></td></tr></table></figure><p>9.查看所有topic的信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper localhost: 2181 --describe </span><br><span class="line">--topic topic-demo 可选参数,表示指定topic</span><br></pre></td></tr></table></figure><p>10.单节点多broker</p><ul><li>修改配合文件中的id,端口,日志文件夹</li><li>启动<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh --deamon ./config/server.properties &amp;</span><br><span class="line">kafka-server-start.sh --deamon ./config/server2.properties &amp;</span><br><span class="line">kafka-server-start.sh --deamon ./config/server3.properties &amp;</span><br></pre></td></tr></table></figure></li><li>多副本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper localhost: 2181/kafka --create --topic my-topic-demo --replication-factor 3 --partitions 1</span><br></pre></td></tr></table></figure></li></ul><h3 id="九-安装scala"><a href="#九-安装scala" class="headerlink" title="九.安装scala"></a>九.安装scala</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/scala-2.11.0<span class="comment"># tar -zxvf scala-2.11.0.tgz </span></span><br><span class="line">root@ubuntu:~/software/scala-2.11.0<span class="comment"># gedit /root/.bashrc </span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#SCALA_HOME</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/root/software/scala-2.11.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SCALA_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.刷新环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/scala-2.11.0<span class="comment"># source /root/.bashrc </span></span><br></pre></td></tr></table></figure><p>3.测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/scala-2.11.0<span class="comment"># scala</span></span><br><span class="line">Welcome to Scala version 2.11.0 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_11).</span><br><span class="line">Type <span class="keyword">in</span> expressions to have them evaluated.</span><br><span class="line">Type :<span class="built_in">help</span> <span class="keyword">for</span> more information.</span><br><span class="line"></span><br><span class="line">scala&gt; </span><br></pre></td></tr></table></figure><h3 id="十-安装maven"><a href="#十-安装maven" class="headerlink" title="十.安装maven"></a>十.安装maven</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software<span class="comment"># tar -zxvf apache-maven-3.8.5-bin.tar.gz</span></span><br><span class="line">root@ubuntu:~/software<span class="comment"># mv apache-maven-3.8.5 maven-3.8.5</span></span><br><span class="line">root@ubuntu:~/software<span class="comment"># gedit /root/.bashrc </span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#MAVEN_HOME</span></span><br><span class="line"><span class="built_in">export</span> MAVEN_HOME=/root/software/maven-3.8.5</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$MAVEN_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.刷新环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/scala-2.11.0<span class="comment"># source /root/.bashrc </span></span><br></pre></td></tr></table></figure><p>3.测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/maven-3.8.5<span class="comment"># mvn -v</span></span><br><span class="line">Apache Maven 3.8.5 (3599d3414f046de2324203b78ddcf9b5e4388aa0)</span><br><span class="line">Maven home: /root/software/maven-3.8.5</span><br><span class="line">Java version: 1.8.0_11, vendor: Oracle Corporation, runtime: /root/software/jdk1.8.0_11/jre</span><br><span class="line">Default locale: en_US, platform encoding: UTF-8</span><br><span class="line">OS name: <span class="string">&quot;linux&quot;</span>, version: <span class="string">&quot;5.4.0-100-generic&quot;</span>, <span class="built_in">arch</span>: <span class="string">&quot;amd64&quot;</span>, family: <span class="string">&quot;unix&quot;</span></span><br></pre></td></tr></table></figure><p>4.修改jar包存放位置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software/maven-3.8.5<span class="comment"># mkdir maven-repos</span></span><br><span class="line">root@ubuntu:~/software/maven-3.8.5<span class="comment"># gedit conf/settings.xml </span></span><br></pre></td></tr></table></figure><p>添加一行</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>/root/software/maven-3.8.5/maven-repos<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="十一-Hbase安装"><a href="#十一-Hbase安装" class="headerlink" title="十一.Hbase安装"></a>十一.Hbase安装</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software<span class="comment"># tar -zxvf hbase-1.2.0-bin.tar.gz </span></span><br><span class="line">root@ubuntu:~/software<span class="comment"># gedit /root/.bashrc </span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HBASE_HOME</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/root/software/hbase-1.2.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HBASE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.刷新环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software<span class="comment"># source /root/.bashrc </span></span><br></pre></td></tr></table></figure><p>3.编辑配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hbase-1.2.0/conf<span class="comment"># gedit hbase-env.sh</span></span><br></pre></td></tr></table></figure><p>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#export JAVA_HOME=/usr/java/jdk1.6.0/</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/root/software/jdk1.8.0_11</span><br></pre></td></tr></table></figure><p>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export HBASE_MANAGES_ZK=true</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hbase-1.2.0/conf<span class="comment"># gedit hbase-site.xml </span></span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.info.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>60010<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hbase-1.2.0/conf<span class="comment"># gedit regionservers </span></span><br></pre></td></tr></table></figure><p>为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure><p>4.启动hbase<br>首先要先启动zeekeeper</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software<span class="comment"># zkServer.sh start</span></span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /root/software/zookeeper-3.4.5-cdh5.6.0/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software<span class="comment"># start-hbase.sh </span></span><br><span class="line">starting master, logging to /root/software/hbase-1.2.0/logs/hbase-root-master-master.out</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed <span class="keyword">in</span> 8.0</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed <span class="keyword">in</span> 8.0</span><br><span class="line">master: starting regionserver, logging to /root/software/hbase-1.2.0/bin/../logs/hbase-root-regionserver-master.out</span><br><span class="line">master: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed <span class="keyword">in</span> 8.0</span><br><span class="line">master: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed <span class="keyword">in</span> 8.0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hbase-1.2.0/bin<span class="comment"># jps</span></span><br><span class="line">2992 SecondaryNameNode</span><br><span class="line">4514 QuorumPeerMain</span><br><span class="line">3282 NodeManager</span><br><span class="line">6196 HRegionServer</span><br><span class="line">3143 ResourceManager</span><br><span class="line">6026 HMaster</span><br><span class="line">6330 Jps</span><br><span class="line">2636 NameNode</span><br><span class="line">2796 DataNode</span><br></pre></td></tr></table></figure><p>访问</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:60010</span><br></pre></td></tr></table></figure><p>6.测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/hbase-1.2.0/bin<span class="comment"># hbase shell</span></span><br><span class="line"></span><br><span class="line">hbase(main):001:0&gt; version</span><br><span class="line">1.2.0, r25b281972df2f5b15c426c8963cbf77dd853a5ad, Thu Feb 18 23:01:49 CST 2016</span><br></pre></td></tr></table></figure><h3 id="十二-Spark安装"><a href="#十二-Spark安装" class="headerlink" title="十二.Spark安装"></a>十二.Spark安装</h3><p>1.解压并配置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software<span class="comment"># tar -zxvf spark-2.1.1-bin-hadoop2.7.tgz </span></span><br><span class="line">root@ubuntu:~/software<span class="comment"># gedit /root/.bashrc </span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#SPARK_HOME</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/root/software/spark-2.1.1-bin-hadoop2.7</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p>2.刷新环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~/software<span class="comment"># source /root/.bashrc </span></span><br></pre></td></tr></table></figure><p>3.测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@master:~/software/spark-2.1.1-bin-hadoop2.7<span class="comment"># spark-shell --version</span></span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 2.1.1</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string">                        </span></span><br><span class="line"><span class="string">Using Scala version 2.11.8, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_11</span></span><br><span class="line"><span class="string">Branch </span></span><br><span class="line"><span class="string">Compiled by user jenkins on 2017-04-25T23:51:10Z</span></span><br><span class="line"><span class="string">Revision </span></span><br><span class="line"><span class="string">Url </span></span><br><span class="line"><span class="string">Type --help for more information.</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><h3 id="十三-flume对接kafka"><a href="#十三-flume对接kafka" class="headerlink" title="十三.flume对接kafka"></a>十三.flume对接kafka</h3><p>一般flume采集的方式有两种<br>1.Exec类型的Source<br>可以将命令产生的输出作为源，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /tmp/log.txt //此处输入命令</span><br></pre></td></tr></table></figure><p>2.Spooling Directory类型的 Source<br>将指定的文件加入到“自动搜集 ”目录中。flume会持续监听这个目录，把文件当做source来处理。注意：一旦文件被放到“自动收集”目录中后，便不能修改，如果修改，flume会报错。此外，也不能有重名的文件，如果有，flume也会报错。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line">a1.sources.r1.spoolDir = /home/work/data</span><br></pre></td></tr></table></figure><h4 id="1-flume采集某日志文件到kafka自定义topic"><a href="#1-flume采集某日志文件到kafka自定义topic" class="headerlink" title="1.flume采集某日志文件到kafka自定义topic"></a>1.flume采集某日志文件到kafka自定义topic</h4><p>1.1 创建flume配置文件 flume-kafka-file.conf</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义这个agent中各组件的名字</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置source组件：r1</span></span><br><span class="line">a1.sources.r1.type = <span class="built_in">exec</span></span><br><span class="line">a1.sources.r1.command = <span class="built_in">tail</span> -F /tmp/log.txt</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置sink组件：k1</span></span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.kafka.topic = topic-test</span><br><span class="line">a1.sinks.k1.kafka.bootstrap.servers = localhost:9092</span><br><span class="line">a1.sinks.k1.kafka.flumeBatchSize = 20</span><br><span class="line">a1.sinks.k1.kafka.producer.acks = 1</span><br><span class="line">a1.sinks.k1.kafka.producer.linger.ms = 1</span><br><span class="line">a1.sinks.ki.kafka.producer.compression.type = snappy</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置channel组件，此处使用是内存缓存的方式</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置source  channel   sink之间的连接关系</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>1.2 启动zookeeper和kafka</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./zkServer.sh start</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /root/software/zookeeper-3.4.5-cdh5.6.0/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... already running as process 5452.</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh ./config/server.properties</span><br></pre></td></tr></table></figure><p>1.3 创建topic</p><p>topic:指定topic name</p><p>partitions:指定分区数，这个参数需要根据broker数和数据量决定，正常情况下，每个broker上两个partition最好</p><p>replication-factor:副本数，建议设置为2</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper localhost: 2181/kafka --create --topic topic-test2 --replication-factor 1 --partitions 1</span><br></pre></td></tr></table></figure><p>1.4 启动kafka去消费topic</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-test2</span><br><span class="line">--from-beginning 可选参数,代表从头消费</span><br></pre></td></tr></table></figure><p>1.5 启动flume</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flume-ng agent -n a1 -c ./conf/ -f ./conf/flume-kafka-port.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p>1.6 向日志文件&#x2F;tmp&#x2F;log.txt写入一些数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &#x27;123&#x27; &gt;&gt; /tmp/log.txt</span><br></pre></td></tr></table></figure><p>就可以在消费者窗口看到输出</p><h4 id="2-flume采集端口数据到kafka自定义topic"><a href="#2-flume采集端口数据到kafka自定义topic" class="headerlink" title="2.flume采集端口数据到kafka自定义topic"></a>2.flume采集端口数据到kafka自定义topic</h4><p>2.1 新建配置文件 flume-kafka-port.conf</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置source组件：r1</span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 55555 </span><br><span class="line"><span class="comment"># 描述和配置sink组件：k1</span></span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.kafka.topic = topic-test2</span><br><span class="line">a1.sinks.k1.kafka.bootstrap.servers = localhost:9092</span><br><span class="line">a1.sinks.k1.kafka.flumeBatchSize = 20</span><br><span class="line">a1.sinks.k1.kafka.producer.acks = 1</span><br><span class="line">a1.sinks.k1.kafka.producer.linger.ms = 1</span><br><span class="line">a1.sinks.ki.kafka.producer.compression.type = snappy</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置channel组件，此处使用是内存缓存的方式</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 描述和配置source  channel   sink之间的连接关系</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>2.2所有操作与上文一致<br>略</p><p>2.3 向端口发送数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:~# nc localhost 55555</span><br><span class="line">OK</span><br><span class="line">ls</span><br><span class="line">OK</span><br><span class="line">ls</span><br><span class="line">OK</span><br><span class="line">ls</span><br><span class="line">OK</span><br><span class="line">ls</span><br><span class="line">OK</span><br><span class="line">ls</span><br></pre></td></tr></table></figure><p>在消费者端口可以看到</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span></span><br><span class="line"><span class="built_in">ls</span></span><br><span class="line"><span class="built_in">ls</span></span><br><span class="line"><span class="built_in">ls</span></span><br><span class="line"><span class="built_in">ls</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一-配置ip-三个节点&quot;&gt;&lt;a href=&quot;#一-配置ip-三个节点&quot; class=&quot;headerlink&quot; title=&quot;一.配置ip(三个节点)&quot;&gt;&lt;/a&gt;一.配置ip(三个节点)&lt;/h3&gt;&lt;p&gt;自ubuntu17之后多了一种配置方式更加高效,也就是netpl</summary>
      
    
    
    
    
  </entry>
  
</feed>
