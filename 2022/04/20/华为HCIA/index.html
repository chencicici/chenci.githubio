<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.11.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="大数据概述&amp;解决办法大数据的特征（5v+1c）: 大量：数据量巨大，MB,GB,TB,PB 多样：数据类型多样，数据来源多样 数据来源：服务器日志、网站浏览信息、社交结构化数据：表格数据 平台、摄像头信息半结构化数据：网页html、xml非结构化数据：视频、音频、图片、文字 高速：数据产生速度快、数据处理速度快 价值：价值密度低 准确：数据真实性 复杂：数据产生速度快、数据的类型多样等特征">
<meta property="og:type" content="article">
<meta property="og:title" content="华为HCIA">
<meta property="og:url" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/index.html">
<meta property="og:site_name" content="Chenci&#39;s blog">
<meta property="og:description" content="大数据概述&amp;解决办法大数据的特征（5v+1c）: 大量：数据量巨大，MB,GB,TB,PB 多样：数据类型多样，数据来源多样 数据来源：服务器日志、网站浏览信息、社交结构化数据：表格数据 平台、摄像头信息半结构化数据：网页html、xml非结构化数据：视频、音频、图片、文字 高速：数据产生速度快、数据处理速度快 价值：价值密度低 准确：数据真实性 复杂：数据产生速度快、数据的类型多样等特征">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_1.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_2.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_3.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_4.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_5.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_6.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_7.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_8.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_9.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_10.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_11.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_12.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_13.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_14.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_15.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_16.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_17.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_18.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_19.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_20.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_21.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_22.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_23.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_24.png">
<meta property="og:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_25.png">
<meta property="article:published_time" content="2022-04-20T06:28:15.000Z">
<meta property="article:modified_time" content="2022-04-20T12:08:30.117Z">
<meta property="article:author" content="chenci">
<meta property="article:tag" content="HCIA">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img.png">


<link rel="canonical" href="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/","path":"2022/04/20/华为HCIA/","title":"华为HCIA"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>华为HCIA | Chenci's blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Chenci's blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Chenci's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0-amp-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">大数据概述&amp;解决办法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E7%89%B9%E5%BE%81%EF%BC%885v-1c%EF%BC%89"><span class="nav-number">1.1.</span> <span class="nav-text">大数据的特征（5v+1c）:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="nav-number">1.2.</span> <span class="nav-text">大数据处理流程：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BB%BB%E5%8A%A1%E7%B1%BB%E5%9E%8B%EF%BC%9A"><span class="nav-number">1.2.1.</span> <span class="nav-text">大数据任务类型：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AE%A1%E7%AE%97%E7%B1%BB%E5%9E%8B%EF%BC%88%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%B1%BB%E5%9E%8B%EF%BC%89"><span class="nav-number">1.3.</span> <span class="nav-text">大数据的计算类型（数据处理类型）:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">1.4.</span> <span class="nav-text">大数据解决方案:</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="nav-number">2.</span> <span class="nav-text">HDFS分布式文件系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="nav-number">2.1.</span> <span class="nav-text">HDFS (Hadoop分布式文件系统)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E7%89%B9%E6%80%A7"><span class="nav-number">2.2.</span> <span class="nav-text">HDFS特性:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">2.3.</span> <span class="nav-text">HDFS适用场景:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9A%E4%BB%80%E4%B9%88"><span class="nav-number">2.4.</span> <span class="nav-text">HDFS不适合做什么:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%80%82%E5%90%88%E5%A4%A7%E9%87%8F%E5%B0%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">2.5.</span> <span class="nav-text">HDFS为什么不适合大量小文件存储</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">2.6.</span> <span class="nav-text">HDFS系统架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E5%8D%95NameNode%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">2.7.</span> <span class="nav-text">HDFS单NameNode的问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-HA%E7%89%B9%E6%80%A7-%E4%B8%BB%E5%A4%87%E9%85%8D%E7%BD%AE"><span class="nav-number">2.8.</span> <span class="nav-text">HDFS HA特性(主备配置)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E7%9A%84%E8%81%94%E9%82%A6%E6%9C%BA%E5%88%B6"><span class="nav-number">2.9.</span> <span class="nav-text">HDFS的联邦机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E5%85%83%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96-%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5"><span class="nav-number">2.10.</span> <span class="nav-text">HDFS元数据持久化(主备同步)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6-3%E4%BB%BD"><span class="nav-number">2.11.</span> <span class="nav-text">HDFS副本机制 (3份)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B"><span class="nav-number">2.12.</span> <span class="nav-text">HDFS读取流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B"><span class="nav-number">2.13.</span> <span class="nav-text">HDFS写入流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ZooKeeper"><span class="nav-number">3.</span> <span class="nav-text">ZooKeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E7%89%B9%E6%80%A7"><span class="nav-number">3.1.</span> <span class="nav-text">ZooKeeper的特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper%E9%9B%86%E7%BE%A4%E4%B8%BB%E4%BB%8E%E9%80%89%E4%B8%BE-x2F-%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2"><span class="nav-number">3.2.</span> <span class="nav-text">ZooKeeper集群主从选举&#x2F;主备切换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E5%AE%B9%E7%81%BE%E8%83%BD%E5%8A%9B"><span class="nav-number">3.3.</span> <span class="nav-text">ZooKeeper的容灾能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E8%AF%BB%E7%89%B9%E6%80%A7"><span class="nav-number">3.4.</span> <span class="nav-text">ZooKeeper的读特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZooKeeper%E7%9A%84%E5%86%99%E7%89%B9%E6%80%A7"><span class="nav-number">3.5.</span> <span class="nav-text">ZooKeeper的写特性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MapReduce"><span class="nav-number">4.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E7%9A%84%E7%89%B9%E6%80%A7-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97"><span class="nav-number">4.1.</span> <span class="nav-text">MapReduce的特性:分布式计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E4%BB%BB%E5%8A%A1"><span class="nav-number">4.2.</span> <span class="nav-text">MapReduce任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Map%E9%98%B6%E6%AE%B5%E8%AF%A6%E6%83%85"><span class="nav-number">4.3.</span> <span class="nav-text">Map阶段详情</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Map%E9%98%B6%E6%AE%B5%E8%AF%A6%E6%83%85-1"><span class="nav-number">4.4.</span> <span class="nav-text">Map阶段详情</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1%E6%A1%88%E4%BE%8B-%E5%8D%95%E8%AF%8D%E8%AE%A1%E6%95%B0WordCount"><span class="nav-number">4.5.</span> <span class="nav-text">词频统计案例(单词计数WordCount)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce%E7%BC%BA%E7%82%B9"><span class="nav-number">4.6.</span> <span class="nav-text">MapReduce缺点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce-V1%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">4.7.</span> <span class="nav-text">MapReduce V1资源调度出现的问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Yarn"><span class="nav-number">5.</span> <span class="nav-text">Yarn</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Yarn%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.</span> <span class="nav-text">Yarn的系统架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce-On-Yarn%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="nav-number">5.2.</span> <span class="nav-text">MapReduce On Yarn任务处理流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HBase"><span class="nav-number">6.</span> <span class="nav-text">HBase</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E7%9A%84%E7%89%B9%E6%80%A7"><span class="nav-number">6.1.</span> <span class="nav-text">HBase的特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%A2%E5%90%91%E5%88%97%E3%80%81%E9%9D%A2%E5%90%91%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">6.2.</span> <span class="nav-text">面向列、面向行数据库的优缺点:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E5%92%8CRDB-%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93-%E7%9A%84%E5%8C%BA%E5%88%AB%E6%AF%94%E8%BE%83"><span class="nav-number">6.3.</span> <span class="nav-text">HBase和RDB (关系型数据库)的区别比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.4.</span> <span class="nav-text">HBase数据模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E7%9A%84%E8%A1%A8%E7%BB%93%E6%9E%84"><span class="nav-number">6.5.</span> <span class="nav-text">HBase的表结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">6.6.</span> <span class="nav-text">HBase系统架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Region%E6%8B%86%E5%88%86"><span class="nav-number">6.7.</span> <span class="nav-text">Region拆分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Region%E5%AE%9A%E4%BD%8D"><span class="nav-number">6.8.</span> <span class="nav-text">Region定位</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HRegionServerBR"><span class="nav-number">6.9.</span> <span class="nav-text">HRegionServerBR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HLog%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-number">6.10.</span> <span class="nav-text">HLog的工作原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E5%88%B7%E5%86%99-%E6%8A%8AMemStore%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%88%B0StoreFile%E4%B8%AD"><span class="nav-number">6.11.</span> <span class="nav-text">缓存刷写(把MemStore数据写入到StoreFile中)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#StoreFile%E7%9A%84%E5%90%88%E5%B9%B6"><span class="nav-number">6.12.</span> <span class="nav-text">StoreFile的合并</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B"><span class="nav-number">6.13.</span> <span class="nav-text">HBase读取流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B"><span class="nav-number">6.14.</span> <span class="nav-text">HBase写入流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BloomFilter-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="nav-number">6.15.</span> <span class="nav-text">BloomFilter (布隆过滤器)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HBase-Shell%E5%91%BD%E4%BB%A4"><span class="nav-number">6.16.</span> <span class="nav-text">HBase Shell命令</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hive"><span class="nav-number">7.</span> <span class="nav-text">Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%94%9F%E6%80%81%E5%9C%88"><span class="nav-number">7.1.</span> <span class="nav-text">Hadoop生态圈</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"><span class="nav-number">7.2.</span> <span class="nav-text">Hive数据模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%88%86%E5%B1%82-%E9%80%BB%E8%BE%91%E5%88%86%E5%B1%82"><span class="nav-number">7.3.</span> <span class="nav-text">Hive数据仓库分层(逻辑分层)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive%E7%9A%84%E5%88%86%E5%B1%82%E5%A4%84%E7%90%86%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">7.4.</span> <span class="nav-text">Hive的分层处理的优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive-SQL%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">7.5.</span> <span class="nav-text">Hive SQL的使用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Spark"><span class="nav-number">8.</span> <span class="nav-text">Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E7%89%B9%E7%82%B9"><span class="nav-number">8.1.</span> <span class="nav-text">Spark特点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD-%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86%E3%80%81%E5%8F%AF%E5%88%86%E5%8C%BA%E7%9A%84"><span class="nav-number">8.2.</span> <span class="nav-text">RDD:分布式数据集、可分区的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96%E7%B1%BB%E5%9E%8B"><span class="nav-number">8.3.</span> <span class="nav-text">依赖类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Stage%E5%88%92%E5%88%86"><span class="nav-number">8.4.</span> <span class="nav-text">Stage划分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD%E6%93%8D%E4%BD%9C%E7%B1%BB%E5%9E%8B"><span class="nav-number">8.5.</span> <span class="nav-text">RDD操作类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD%E3%80%81DataFrame%E3%80%81-DataSet%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%81%94%E7%B3%BB"><span class="nav-number">8.6.</span> <span class="nav-text">RDD、DataFrame、 DataSet数据集的联系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84"><span class="nav-number">8.7.</span> <span class="nav-text">Spark体系架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Streaming"><span class="nav-number">9.</span> <span class="nav-text">Streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7-%E5%AE%9E%E6%97%B6%E5%93%8D%E5%BA%94%EF%BC%8C%E5%BB%B6%E8%BF%9F%E6%80%A7%E4%BD%8E"><span class="nav-number">9.1.</span> <span class="nav-text">关键特性:实时响应，延迟性低</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Streaming%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">9.2.</span> <span class="nav-text">Streaming系统架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Streaming%E4%BB%BB%E5%8A%A1%E6%9E%B6%E6%9E%84"><span class="nav-number">9.3.</span> <span class="nav-text">Streaming任务架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Streaming%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1"><span class="nav-number">9.4.</span> <span class="nav-text">Streaming执行任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A0%B9%E6%8D%AE%E4%BB%BB%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%89%A7%E8%A1%8C"><span class="nav-number">9.5.</span> <span class="nav-text">根据任务架构执行</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E8%AF%AD%E4%B9%89"><span class="nav-number">9.6.</span> <span class="nav-text">消息传递语义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ack%E6%9C%BA%E5%88%B6-%E6%B6%88%E6%81%AF%E4%BC%A0%E8%BE%93%E6%9C%80%E5%B0%91%E4%B8%80%E6%AC%A1"><span class="nav-number">9.7.</span> <span class="nav-text">Ack机制(消息传输最少一次)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fink"><span class="nav-number">10.</span> <span class="nav-text">Fink</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink-VS-Spark-Streaming"><span class="nav-number">10.1.</span> <span class="nav-text">Flink VS Spark Streaming</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink%E7%9A%84%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7"><span class="nav-number">10.2.</span> <span class="nav-text">Flink的关键特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-number">10.3.</span> <span class="nav-text">Flink系统架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%89%E7%95%8C%E6%B5%81%E5%92%8C%E6%97%A0%E7%95%8C%E6%B5%81"><span class="nav-number">10.4.</span> <span class="nav-text">有界流和无界流</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataStream-%E7%94%A8%E4%BA%8E%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E5%8F%AA%E8%83%BD%E6%89%A7%E8%A1%8C%E6%B5%81%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C"><span class="nav-number">10.5.</span> <span class="nav-text">DataStream:用于存储数据的数据集，只能执行流处理操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataSet-%E7%94%A8%E6%9D%A5%E6%8E%A5%E6%94%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E5%8F%AA%E8%83%BD%E6%89%A7%E8%A1%8C%E6%89%B9%E5%A4%84%E7%90%86%E6%93%8D%E4%BD%9C"><span class="nav-number">10.6.</span> <span class="nav-text">DataSet:用来接收数据的数据集，只能执行批处理操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Flink%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-number">10.7.</span> <span class="nav-text">Flink运行流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">10.8.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fink%E7%9A%84%E6%9E%B6%E6%9E%84%E5%92%8C%E5%8E%9F%E7%90%86"><span class="nav-number">10.9.</span> <span class="nav-text">Fink的架构和原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fink%E7%9A%84Time%E5%92%8CWindow"><span class="nav-number">10.10.</span> <span class="nav-text">Fink的Time和Window</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fink%E7%9A%84Watermark"><span class="nav-number">10.11.</span> <span class="nav-text">Fink的Watermark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fink%E7%9A%84%E5%AE%B9%E9%94%99"><span class="nav-number">10.12.</span> <span class="nav-text">Fink的容错</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="chenci"
      src="/images/IMG_0010.JPG">
  <!--
  <p class="site-author-name" itemprop="name">chenci</p>
  -->
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/chencicici" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chencicici" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1343369483@qq.com" title="E-Mail → mailto:1343369483@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.uodrad.top/" title="https:&#x2F;&#x2F;www.uodrad.top&#x2F;" rel="noopener" target="_blank">uodrad</a>
        </li>
    </ul>
  </div>


       <!--网易云插件-->
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1933503036&auto=1&height=66">
      </iframe>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/chencicici" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0010.JPG">
      <meta itemprop="name" content="chenci">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chenci's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="华为HCIA | Chenci's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          华为HCIA
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-04-20 14:28:15 / 修改时间：20:08:30" itemprop="dateCreated datePublished" datetime="2022-04-20T14:28:15+08:00">2022-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="大数据概述-amp-解决办法"><a href="#大数据概述-amp-解决办法" class="headerlink" title="大数据概述&amp;解决办法"></a>大数据概述&amp;解决办法</h1><h2 id="大数据的特征（5v-1c）"><a href="#大数据的特征（5v-1c）" class="headerlink" title="大数据的特征（5v+1c）:"></a>大数据的特征（5v+1c）:</h2><ul>
<li>大量：数据量巨大，MB,GB,TB,PB</li>
<li>多样：数据类型多样，数据来源多样 数据来源：服务器日志、网站浏览信息、社交<br>结构化数据：表格数据 平台、摄像头信息<br>半结构化数据：网页html、xml<br>非结构化数据：视频、音频、图片、文字</li>
<li>高速：数据产生速度快、数据处理速度快</li>
<li>价值：价值密度低</li>
<li>准确：数据真实性</li>
<li>复杂：数据产生速度快、数据的类型多样等特征，导致做数据处理时处理过程变得很复杂</li>
</ul>
<h2 id="大数据处理流程："><a href="#大数据处理流程：" class="headerlink" title="大数据处理流程："></a>大数据处理流程：</h2><p>数据采集-&gt;数据预处理-&gt;数据存储-&gt;分析挖掘-&gt;数据可视化</p>
<h3 id="大数据任务类型："><a href="#大数据任务类型：" class="headerlink" title="大数据任务类型："></a>大数据任务类型：</h3><ul>
<li>IO密集型任务：大量输入输出请求的任务，。资源</li>
<li>计算密集型任务：有大量的计算要求，CPU资源</li>
<li>数据密集型任务：数据处理，并发数据处理</li>
</ul>
<h2 id="大数据的计算类型（数据处理类型）"><a href="#大数据的计算类型（数据处理类型）" class="headerlink" title="大数据的计算类型（数据处理类型）:"></a>大数据的计算类型（数据处理类型）:</h2><ul>
<li>批处理：一次处理一批量数据，处理的数据量大，但是延迟性高</li>
<li>流处理：一次处理一条数据，处理的数据量小，但是延迟性低</li>
<li>图处理：以图的形式展示数据，进行处理</li>
<li>查询分析计算：检索功能</li>
</ul>
<h2 id="大数据解决方案"><a href="#大数据解决方案" class="headerlink" title="大数据解决方案:"></a>大数据解决方案:</h2><p>Fusioninsight HD:部署在x86架构上<br>BigData pro:部署在ARM架构上<br>MapReduce Server （MRS）:部署华为云服务上</p>
<ul>
<li>高性能：支持自我研发的存储系统CarbonData</li>
<li>易运维：提供了可视化的管理界面</li>
<li>高安全：使用Kerborse &amp; Ldap实现认证管理和权限管理</li>
<li>低成本：按需购买，自定义配置底层架构性能</li>
</ul>
<h1 id="HDFS分布式文件系统"><a href="#HDFS分布式文件系统" class="headerlink" title="HDFS分布式文件系统"></a>HDFS分布式文件系统</h1><h2 id="HDFS-Hadoop分布式文件系统"><a href="#HDFS-Hadoop分布式文件系统" class="headerlink" title="HDFS (Hadoop分布式文件系统)"></a>HDFS (Hadoop分布式文件系统)</h2><ul>
<li>创建人:道格卡廷</li>
<li>起始原因:开发一个搜索引擎–&gt;存储问题(大量数据的存储)</li>
<li>google论文: GFS - google自身的分布式文件系统 <code>闭源</code></li>
</ul>
<h2 id="HDFS特性"><a href="#HDFS特性" class="headerlink" title="HDFS特性:"></a>HDFS特性:</h2><p>理论上HDFS存储可以无限扩展</p>
<ul>
<li>分布式:把多节点的存储系统结合为一一个整体对外提供服务(提高存储能力)</li>
<li>容错性:针对每个数据存储备份(默认3份)，备份存储分别存在不同的位置，如果备份或者数据有丢失，会再进行备份，保持一直都是3份</li>
<li>按块存储:块大小默认128M, 一个文件可以存储在多个块,<code>但是一个块只存储一个文件</code> <br><code>好处:数据丢失针对丢失的数据所属的块，只恢复当前块就可以</code></li>
<li>元数据:记录文件存储在哪些块,块存储在哪里等信息 <br>每个块都有一个元数据信息，并且元数据的大小是固定的150K</li>
</ul>
<h2 id="HDFS适用场景"><a href="#HDFS适用场景" class="headerlink" title="HDFS适用场景:"></a>HDFS适用场景:</h2><ul>
<li>可以做大文件</li>
<li>可以协助离线处理或批处理</li>
<li>流式数据访问机制</li>
</ul>
<h2 id="HDFS不适合做什么"><a href="#HDFS不适合做什么" class="headerlink" title="HDFS不适合做什么:"></a>HDFS不适合做什么:</h2><ul>
<li>不适合大量小文件存储</li>
<li>不适合做实时场景</li>
<li>不适合随机读写，可以做追加写</li>
</ul>
<h2 id="HDFS为什么不适合大量小文件存储"><a href="#HDFS为什么不适合大量小文件存储" class="headerlink" title="HDFS为什么不适合大量小文件存储"></a><code>HDFS为什么不适合大量小文件存储</code></h2><pre><code>(例: 10个文件，每个文件大小为20M)
</code></pre>
<ol>
<li>10个文件需要使用10个块，并且每个块只是用了20M空间—&gt; 存储空间浪费</li>
<li>有10个元数据，元数据150K</li>
<li>寻址时间增长</li>
</ol>
<p>不适合随机读写，可以做追加写</p>
<h2 id="HDFS系统架构"><a href="#HDFS系统架构" class="headerlink" title="HDFS系统架构"></a>HDFS系统架构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img.png" alt="HDFS系统架构"></p>
<ul>
<li>Client (客户端) :用户接口，用户通过Client连接到组件</li>
<li>NameNode (名称节点，主节点) :管理DataNode,并且接收用户请求,分发任务，存储元数据信息</li>
<li>DataNode (数据节点，从节点) :实际处理用户请求，维护自己的Block和实际存储位置映射关系</li>
<li>Block (块) : 数据存储</li>
</ul>
<h2 id="HDFS单NameNode的问题"><a href="#HDFS单NameNode的问题" class="headerlink" title="HDFS单NameNode的问题"></a>HDFS单NameNode的问题</h2><ul>
<li>单名称节点故障:整个集群都无法使用—&gt;HA(主备配置)</li>
<li>单名称节点性能瓶颈问题:并发处理的任务量有限—-&gt;联邦机制</li>
</ul>
<h2 id="HDFS-HA特性-主备配置"><a href="#HDFS-HA特性-主备配置" class="headerlink" title="HDFS HA特性(主备配置)"></a>HDFS HA特性(主备配置)</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_1.png" alt="HA特性"></p>
<ul>
<li>active节点:对外提供服务</li>
<li>standby节点:不断备份active节点的数据，<code>当active宕机,standby会成为新的active</code></li>
<li>zookeeper监测主节点的状态，一旦发现故障，zookeeper就通知备用节点成为新的主节点</li>
</ul>
<h2 id="HDFS的联邦机制"><a href="#HDFS的联邦机制" class="headerlink" title="HDFS的联邦机制"></a>HDFS的联邦机制</h2><pre><code>各个NN之间是相互隔离的，维护自己的命名空间
</code></pre>
<p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_2.png" alt="联邦机制"></p>
<h2 id="HDFS元数据持久化-主备同步"><a href="#HDFS元数据持久化-主备同步" class="headerlink" title="HDFS元数据持久化(主备同步)"></a>HDFS元数据持久化(主备同步)</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_3.png" alt="元数据持久化"></p>
<ol>
<li>备节点会通知主节点新建一个Editlog.new文件， 从这之后的操作都记录在.new文件中</li>
<li>备节点从主节点拷贝Editlog、Fsimage文件(只有第一 次需要 下载Fsimage,后续同步使用本地的)</li>
<li>将两个文件进行合并，生成Fsimage.ckpt文件</li>
<li>备节点将Fsimage.ckpt上传到主节点上</li>
<li>主节点接收到Fsimage.ckpt恢复成Fsimage</li>
<li>把Editlog.new重命名Editlog</li>
</ol>
<h2 id="HDFS副本机制-3份"><a href="#HDFS副本机制-3份" class="headerlink" title="HDFS副本机制 (3份)"></a>HDFS副本机制 (3份)</h2><ul>
<li>存储副本规则:</li>
</ul>
<ol>
<li>第一份副本存放在同一节点中(传输最快,但是如果节点故障，副本也会丢失)</li>
<li>第二份副本存放在同一机架的不同节点上(如果整个机架故障，副本也会丢失)</li>
<li>第三分副本存放在不同机架的其他节点上</li>
</ol>
<ul>
<li>副本距离公式:<code>优先选择的是距离小的</code></li>
</ul>
<ol>
<li>同节点的距离为0</li>
<li>同一机架不同节点的距离为2</li>
<li>不同机架的节点距离为4</li>
</ol>
<h2 id="HDFS读取流程"><a href="#HDFS读取流程" class="headerlink" title="HDFS读取流程"></a>HDFS读取流程</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_4.png" alt="读取流程"></p>
<ol>
<li>Client向NameNode发起读取请求</li>
<li>NameNode接收到请求，反馈对应的元数据信息给Client</li>
<li>Client接收到反馈请求对应的DataNode <code>(如果Client本地有数据，优先从本地读取)</code></li>
<li>DataNode接收到请求，反馈数据内容给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HDFS写入流程"><a href="#HDFS写入流程" class="headerlink" title="HDFS写入流程"></a>HDFS写入流程</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_5.png" alt="写入流程"></p>
<ol>
<li>Client向NameNode发出写入请求</li>
<li>NameNode接收到请求后生成该文件的元数据信息，反馈DataNode信息给Client</li>
<li>Client接收到DataNode信息之后，请求相对应的DataNode</li>
<li>Client提交文件写入到对应的DataNode</li>
<li>DataNode接收到写入请求，执行写入</li>
<li>Client写入第一-个节点后，由第一个节点写入第二个节点，第二个节点写入第三个节点</li>
<li>写入完成后反馈元数据信息给Client</li>
<li>关闭读取流，NameNode更新元数据信息</li>
</ol>
<h1 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h1><pre><code>分布式服务应用，可以帮助其他分布式组件协调管理集群
</code></pre>
<h2 id="ZooKeeper的特性"><a href="#ZooKeeper的特性" class="headerlink" title="ZooKeeper的特性"></a>ZooKeeper的特性</h2><ul>
<li>分布式服务, ZooKeeper集群中有一半以上的节点存活集群才能正常运行</li>
<li>最终一致性:所有的节点对外提供的是同一个视图</li>
<li>实时性:实时获取、实时反馈应用状态</li>
<li>可靠性: 一条数据被-个节点接收到，就会被其他节点也接收</li>
<li>等待无关性:慢的或者失效的client请求，不会影响到其他客户端请求</li>
<li>原子性:最终状态只有成功或者失败</li>
</ul>
<h2 id="ZooKeeper集群主从选举-x2F-主备切换"><a href="#ZooKeeper集群主从选举-x2F-主备切换" class="headerlink" title="ZooKeeper集群主从选举&#x2F;主备切换"></a>ZooKeeper集群主从选举&#x2F;主备切换</h2><ul>
<li>选举: zookeeper内部投票选举,当节点得到一半以上的票数,它就会称为Leader,其他的节点都是Follower</li>
<li>主备切换:当leader出现故障,从其他的follower中重新选举新的leader</li>
</ul>
<h2 id="ZooKeeper的容灾能力"><a href="#ZooKeeper的容灾能力" class="headerlink" title="ZooKeeper的容灾能力"></a>ZooKeeper的容灾能力</h2><pre><code>(可容灾集群最低要求是3个节点)
</code></pre>
<ul>
<li>在集群运行过程中允许发生故障的节点数(最大:节点数-半-1)</li>
<li>如:集群只要1个节点，容灾能力为0<br>  集群只要2个节点，容灾能力为0<br>  集群只要3个节点，容灾能力为1<br>  集群只要4个节点，容灾能力为1</li>
<li>搭建集群时，尽量选择奇数台节点进行搭建</li>
</ul>
<h2 id="ZooKeeper的读特性"><a href="#ZooKeeper的读特性" class="headerlink" title="ZooKeeper的读特性"></a>ZooKeeper的读特性</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_6.png" alt="读特性"></p>
<ol>
<li>Client发起读取请求</li>
<li>获取到数据(不管接收请求的是Leader节点还是Follower节点)</li>
</ol>
<h2 id="ZooKeeper的写特性"><a href="#ZooKeeper的写特性" class="headerlink" title="ZooKeeper的写特性"></a>ZooKeeper的写特性</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_7.png" alt="写特性"></p>
<ol>
<li>Client发起写入请求 如果请求到的节点不是leader节点，follower会把请求转发给leader</li>
<li>leader接收到请求后会向所有节点发出询问是否可以接收写入</li>
<li>节点接收到询问请求,根据自身情况反馈是否可写入的信息给leader</li>
<li>leader接收到一半以上的节点可以写入，再执行写入</li>
<li>写入完成后反馈给client,如果Client请求的不是leader, leader把写 入状态反馈给follower,由follower反馈给client</li>
</ol>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><pre><code>数据处理(数据计算)
创建者:道格卡廷
出发点:搜索引擎--&gt;处理问题google: mapreduce论文MapReduce的特性:分布式计算
</code></pre>
<h2 id="MapReduce的特性-分布式计算"><a href="#MapReduce的特性-分布式计算" class="headerlink" title="MapReduce的特性:分布式计算"></a>MapReduce的特性:分布式计算</h2><ul>
<li>高度抽象的编程思想:编程人员只需要描述做什么，具体怎么做交由处理框架执行的</li>
<li>可扩展性:分布式、搭建在集群上的一-个处理组件</li>
<li>高容错性:处理任务时节点故障，迁移到其他节点执行任务MapReduce任务主要分为两大部分: map任务、 reduce任务</li>
</ul>
<h2 id="MapReduce任务"><a href="#MapReduce任务" class="headerlink" title="MapReduce任务"></a>MapReduce任务</h2><ul>
<li>reduce任务的处理数据来源是map任务的输出</li>
<li>map阶段:针对每个数据执行一个操作, 提取数据特征</li>
<li>reduce阶段:获取到多个map的输出，统一计 算处理,针对key统计汇总这个key对应的value</li>
</ul>
<h2 id="Map阶段详情"><a href="#Map阶段详情" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_8.png" alt="Map阶段详情"></p>
<ol>
<li>数据从数据源获取后进行分片切分、执行map操作</li>
<li>分片会被存储在环形内存缓冲区( 当缓冲区达到80%会发生溢写)</li>
<li>把分片溢写到磁盘中，生成MOF文件</li>
<li>溢写过程中对数据执行</li>
</ol>
<h2 id="Map阶段详情-1"><a href="#Map阶段详情-1" class="headerlink" title="Map阶段详情"></a>Map阶段详情</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_9.png" alt="Reduce阶段详情"></p>
<ol>
<li>把数据(MOF)从磁盘中加载到内存中</li>
<li>当数据量过大会执行归并，如果不多，直接跳过归并执行归约操作</li>
<li>执行完reduce操作之后，最终结果写入到HDFS</li>
</ol>
<h2 id="词频统计案例-单词计数WordCount"><a href="#词频统计案例-单词计数WordCount" class="headerlink" title="词频统计案例(单词计数WordCount)"></a>词频统计案例(单词计数WordCount)</h2><ol>
<li>数据源(很多英文句子或短语的一个文件)</li>
<li>提取出每个单词,统计单词出现的次数<br><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_10.png" alt="词频统计案例"></li>
</ol>
<h2 id="MapReduce缺点"><a href="#MapReduce缺点" class="headerlink" title="MapReduce缺点"></a>MapReduce缺点</h2><ul>
<li>处理延迟性高</li>
<li>使用java语言编程map处理reduce处理</li>
<li>MapReduce处理任务需要使用资源</li>
</ul>
<h2 id="MapReduce-V1资源调度出现的问题"><a href="#MapReduce-V1资源调度出现的问题" class="headerlink" title="MapReduce V1资源调度出现的问题"></a>MapReduce V1资源调度出现的问题</h2><ul>
<li>如果发生问题，通知用户介入解决</li>
<li>没有区分任务调度和资源调度，都是MR的主节点在处理，主节点的整体工作压力非常大</li>
<li>因为资源没有单独隔离,容易出现资源抢占的问题</li>
</ul>
<h1 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h1><pre><code>资源调度管理服务---&gt; 可以协助其他组件应用协调管理资源，以及任务调度
</code></pre>
<h2 id="Yarn的系统架构"><a href="#Yarn的系统架构" class="headerlink" title="Yarn的系统架构"></a>Yarn的系统架构</h2><pre><code>在集群层面来说只有一个ResourceManager, 多个NodeManager
以程序执行层面来说，一个应用只有一-个AppMaster,多个Container
</code></pre>
<p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_11.png" alt="Yarn的系统架构"></p>
<ul>
<li>Client:客户端</li>
<li>ResourceManager (主节点) :负责资源管理,任务调度</li>
<li>NodeManager (从节点) :负责提供资源，实际任务执行</li>
<li>ApplicationMaster:特殊的Container, 管理同一应用的其他Container,以及实时关注任务执行状态,反馈给RM</li>
<li>Container:<code>资源的抽象</code>，被封装起来的资源，一个Container执行一个任务, 其他任务不能使用这个Container的资源</li>
</ul>
<h2 id="MapReduce-On-Yarn任务处理流程"><a href="#MapReduce-On-Yarn任务处理流程" class="headerlink" title="MapReduce On Yarn任务处理流程"></a><code>MapReduce On Yarn任务处理流程</code></h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_12.png" alt="MapReduce On Yarn任务处理流程"></p>
<ol>
<li>Client向RM发起请求</li>
<li>RM(ApplicationManager)接收到请求后在NM中启动一-个AppMaster</li>
<li>AppMaster接收任务，根据任务向RM (ResourceScheduler) 申请资源</li>
<li>在NM中封装资源Container提供给AppMaster执行应用</li>
<li>执行过程中Container会实时反馈执行状态给AppMaster</li>
<li>AppMaster会反馈任务执行状态和自身状态给RM (ApplicationManager)</li>
<li>AppMaster将运行结果反馈给RM,然后向RM (ResourceScheduler) 申请释放资源</li>
<li>RM将任务情况反馈给Client</li>
</ol>
<p>Yarn搭建时支持主备配置，实现主备ResourceManager<br>AppMaster的容错(当-个AppMaster出现故障,任务管理会被迁移到新的AppMaster)</p>
<p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_13.png" alt="AppMaster的容错"></p>
<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><pre><code>HBase分布式列式NoSQL数据库，底层存储使用的是HDFS ,`没有数据类型，所有数据存储都是字节数组的形式byte[]`
创建者:道格卡廷
出发点:搜索引擎--&gt;提高数据读写速度--&gt; BigTable
</code></pre>
<h2 id="HBase的特性"><a href="#HBase的特性" class="headerlink" title="HBase的特性"></a>HBase的特性</h2><ul>
<li>可扩展性:可以通过添加节点的方式增加数据存储空间</li>
<li>高可靠性:底层使用HDFS,能够保证数据的可靠性，预写式日志保证内存中的数据不丢失</li>
<li>高性能:处理PB级别的数据</li>
<li>面向列: HBase数据存储是面向列的</li>
<li>可伸缩性:动态添加列(在添加数据的时候)-</li>
</ul>
<h2 id="面向列、面向行数据库的优缺点"><a href="#面向列、面向行数据库的优缺点" class="headerlink" title="面向列、面向行数据库的优缺点:"></a>面向列、面向行数据库的优缺点:</h2><ul>
<li>面向行:<br>  优点:能方便快捷的获取一一行记录<br>  缺点:在想要单独获取指定列数据的时候，会检索到其他无关列</li>
<li>面向列:<br>  优点:在检索单列数据时，不会出现无关列<br>  缺点:想要查询一条记录时，需要多次IO请求才能拼出一条记录</li>
</ul>
<h2 id="HBase和RDB-关系型数据库-的区别比较"><a href="#HBase和RDB-关系型数据库-的区别比较" class="headerlink" title="HBase和RDB (关系型数据库)的区别比较"></a>HBase和RDB (关系型数据库)的区别比较</h2><ul>
<li>数据索引: <br>HBase只有一 种索引(rowkey)，RDB中可以配置多个索引</li>
<li>数据维护: <br>HBase允许数据增删查,<code>不支持修改</code>，RDB中允许数据增删查改<br>HBase可以使用覆盖的方式写入数据以此实现数据修改的功能<br>可伸缩性: HBase可以在添加数据时动态添加列，RDB只能通过修改表的方式添加列<br>RDB (MySQL) 数据模型:数据库、表、行、列(字段)，单元格</li>
</ul>
<h2 id="HBase数据模型"><a href="#HBase数据模型" class="headerlink" title="HBase数据模型"></a>HBase数据模型</h2><pre><code>命名空间、表、行、列(组成列族)、单元格(可以存储多条记录)
</code></pre>
<ul>
<li>命名空间: hbase、 default. 自定义(在使用自定义的命名空间时都需要指定命名空间名称)</li>
<li>表:由行和列组成</li>
<li>行:有一个唯一表示行键(rowkey)</li>
<li>列:归属于某一个列族(<code>动态添加</code>)</li>
<li>列族:由一个或多个列组成(创建表时创建的，不能动态更改)</li>
<li>单元格:由行和列能确定-一个单元格，<code>一个单元格中可能存在多条记录(多版本记录，使用时间戳进行区分)</code></li>
</ul>
<h2 id="HBase的表结构"><a href="#HBase的表结构" class="headerlink" title="HBase的表结构"></a>HBase的表结构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_14.png" alt="HBase的表结构"></p>
<pre><code>要找到行列对应的单元格值时，表行键,列族:列
默认情况下，只返回单元格中的最新记录，如果要返回多版本需要指定参数VERSIONS=&gt;3
</code></pre>
<h2 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_15.png" alt="HBase系统架构"></p>
<ul>
<li>Client:用户可以通过Client连接到HBase,基本不与HMaster交互</li>
<li>ZooKeeper:监测HMaster的主备运行状态及主备切换，监测HRegionServer的状态，反馈给HMaster,<code>存储HBase元数据信息hbase:meta</code></li>
<li>Hmaster() ：管理维护HRegionServer列表，管理分配Region, Region负载均衡</li>
<li>HRegionServer：管理分配给它的Region，处理用户的读写请求</li>
<li>DFS Client: HBase连接到HDFS的接口</li>
</ul>
<p>一个HRegionserver中包含一个HLog， 多个HRegion</p>
<ul>
<li><p>HLog:预写式日志WAL,记录数据操作(数据写入之前必须先写入HLog)</p>
</li>
<li><p>Region:<code>分布式存储的最基本单位，刚开始一个Region存储一个表的内容随着数据增多</code>，Region会不断分裂<br>Store:一个Region中包含多个Store,<code>一个Store存储一个列族数据</code><br>MemStore (写缓存):一个Store包含一个MemStore <br>StoreFile (磁盘文件):一个Store中包含多个StoreFile<br>HFile (HDFS文件): 一个StoreFile添加头部信息转换成HFile,最终存储在HDFS中</p>
</li>
<li><p>数据写入关键流程:先写入HLog,然后才能写入MemStore,当MemStore达到溢出要求(128M) ,将数据刷写StoreFile中</p>
</li>
<li><p>数据读取关键流程:先读取MemStore,如果没有,再读取BlockCache (读缓存)，如果还是没有最终才读取StoreFile<br>BlockCache存储之前的用户查询过的数据，当MemStore和BlockCache中都没有数据， 需要从StoreFile<br>中读取数据时，读取完的数据会被加载到BlockCache中</p>
</li>
</ul>
<h2 id="Region拆分"><a href="#Region拆分" class="headerlink" title="Region拆分"></a>Region拆分</h2><ul>
<li>拆分原因:数据不断增加，region不断增大， region过大会影响数据读写速度</li>
<li>拆分条件:根据行键拆分，尽可能将同一个行键或相似的行键放在一个Region中</li>
</ul>
<p>-region拆分过程很快，接近瞬间,在拆分时实际还是请求的原文件,拆分结束之后会将原文件内容异步写入新文件,然后之后的请求被转移到新文件</p>
<h2 id="Region定位"><a href="#Region定位" class="headerlink" title="Region定位"></a>Region定位</h2><p>  元数据信息存储在hbase:meta中,这个表信息被存储在zookeeper内存中通过元数据信息获取Region实际存储位置</p>
<h2 id="HRegionServerBR"><a href="#HRegionServerBR" class="headerlink" title="HRegionServerBR"></a>HRegionServerBR</h2><p>H RegionServer出现故障时</p>
<ol>
<li>zookeeper发现RegionServer故障，同时HMaster</li>
<li>HMaster获取故障的RegionServer上的HLog信息，根据与Region的对应关系对HLog进行拆分</li>
<li>把HLog存放在Region目录下，把Region重新迁移至其他的RegionServer上</li>
<li>其他的RegionServer接收到Region执行重新执行HLog内容</li>
</ol>
<h2 id="HLog的工作原理"><a href="#HLog的工作原理" class="headerlink" title="HLog的工作原理"></a>HLog的工作原理</h2><ul>
<li>HLog: WAL预写式日志，数据更新的操作都要先写入HLog中，才能写入MemStore<br><code>当MemStore被刷写到磁盘后，会向HLog中写入一条标记记录 (标记记录之前的所有数据都已经刷写到磁盘)</code></li>
<li>系统启动时，系统任务先扫描HLog, 检测是否有数据没有写入到磁盘中,如果有先执行写入MemStore,然后再刷写到磁盘，清空缓存,最后再为用户提供服务 <br>如果数据丢失，可以根据HLog重新执行恢复</li>
<li>一个RegionServer只有一-个HLog (共用一个HLog)<br>  优点:写入日志时不需要查找对应的Log,直接全部写入一个HLog<br>  缺点:如果RegionServer出现故障， 需要对HLog进行拆分</li>
</ul>
<h2 id="缓存刷写-把MemStore数据写入到StoreFile中"><a href="#缓存刷写-把MemStore数据写入到StoreFile中" class="headerlink" title="缓存刷写(把MemStore数据写入到StoreFile中)"></a>缓存刷写(把MemStore数据写入到StoreFile中)</h2><ul>
<li>当MemStore达到刷写条件，就会将内容刷写到StoreFile文件中</li>
<li>缓存的刷写是针对整个Region的，当一个MemStore达到刷写要求， 当前的Region下面的所有MemStore都会触发刷写</li>
<li>每次刷写都会生成一个新的StoreFile文件(每次的刷写内容都分别在一个新文件中)</li>
<li>刷写完成之后会在HLog中写入标记记录,并且清空缓存</li>
</ul>
<h2 id="StoreFile的合并"><a href="#StoreFile的合并" class="headerlink" title="StoreFile的合并"></a>StoreFile的合并</h2><pre><code>(刷写操作会出现大量的StoreFile,且部分StoreFile文件大小过小) 合并比较消耗资源,达到一定阈值才会执行
将多个的StoreFile小文件合并成一个大文件,如果StoreFile文件过大，再进行拆分(根据HDFS块进行拆分)
</code></pre>
<p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_16.png" alt="StoreFile的合并"></p>
<p>合并文件会进行筛选:如果本身的StoreFile就已经达到1 00M左右,这个StoreFile是不参与合并的</p>
<h2 id="HBase读取流程"><a href="#HBase读取流程" class="headerlink" title="HBase读取流程"></a>HBase读取流程</h2><ol>
<li>Client请求zookeeper获取hbase:meta表元数据信息，获取RegionServer信息</li>
<li>Client请求相对应的RegionServer</li>
<li>RegionServer接收到请求反馈数据给Client</li>
<li>关闭读取流</li>
</ol>
<h2 id="HBase写入流程"><a href="#HBase写入流程" class="headerlink" title="HBase写入流程"></a>HBase写入流程</h2><ol>
<li>Client请求的zookeeper,获取hbase:meta表信息,根据写入的行键获取对应的RegionServer信息</li>
<li>Client请求RegionServer发起写入请求</li>
<li>RegionServer接收到请求后将数据写入到行键对应的Region中.</li>
<li>RegionServer反馈写入状态给Client</li>
<li>关闭写入流</li>
</ol>
<h2 id="BloomFilter-布隆过滤器"><a href="#BloomFilter-布隆过滤器" class="headerlink" title="BloomFilter (布隆过滤器)"></a>BloomFilter (布隆过滤器)</h2><pre><code>判断数据是否存在，如果反馈结果为不存在，是可信的，如果反馈结果为存在，可能有误差
</code></pre>
<p>缩小数据违取范围<br><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_17.png" alt="布隆过滤器"></p>
<p>在HBase中行键是以字典序进行排序<br><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_18.png" alt="以字典序进行排序"></p>
<h2 id="HBase-Shell命令"><a href="#HBase-Shell命令" class="headerlink" title="HBase Shell命令"></a>HBase Shell命令</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">namespace:</span><br><span class="line">    create_namespace <span class="string">&#x27;名称&#x27;</span></span><br><span class="line">    list_namespace</span><br><span class="line">    list_namespace_ tables <span class="string">&#x27;ns1&#x27;</span></span><br><span class="line">    alter_namespace <span class="string">&#x27;ns1 ,&#123;属性名称=&gt; &#x27;</span>属性值&#125;</span><br><span class="line">    drop_ namespace <span class="string">&#x27;ns1&#x27;</span> <span class="comment">---命名空间需要是空的</span></span><br><span class="line"></span><br><span class="line">ddl:数据定义语言<span class="comment">---&gt; 表层面的操作</span></span><br><span class="line">    <span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>,列族名<span class="number">1</span><span class="string">&#x27;;列族2&#x27;</span></span><br><span class="line">    <span class="keyword">create</span> <span class="string">&#x27;表名,&#123;NAME= &gt; &#x27;</span>列族<span class="string">&#x27; VERSIONS= &gt; 5&#125;,&#123;NAME= &gt;列族&#x27;</span> ,VERSIONS<span class="operator">=</span> <span class="operator">&gt;</span><span class="number">5</span>&#125;</span><br><span class="line">    修改列族属性信息、添加列族: <span class="keyword">alter</span> <span class="string">&#x27;表名&#x27;</span>,&#123;NAME<span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族&#x27;</span> ,VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">5</span>&#125;<span class="comment">--&gt;如果列族存在做修改，不存在做添加</span></span><br><span class="line">    使用list可以查看所有的表:包含<span class="keyword">default</span>命名空间和自定义命名空间中的表</span><br><span class="line">    查看表信息: <span class="keyword">describe</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">    删除表: <span class="keyword">drop</span> <span class="string">&#x27;表名’--&gt; 禁用状态的表才 能进行删除</span></span><br><span class="line"><span class="string">    禁用表: disable 表名&#x27;</span> <span class="operator">/</span>启用表: enable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">    </span><br><span class="line">dml:数据管理语言<span class="comment">--&gt; 针对数据层面的操作</span></span><br><span class="line">    添加数据: put <span class="string">&#x27;表名，’行键&quot;,列族:列&quot;,值’--&gt; 默认使用的是系统时间戳</span></span><br><span class="line"><span class="string">    删除数据: delete &#x27;</span>表名&quot;;行键’</span><br><span class="line">    delete表名&#x27;,行键&quot;，列族:列<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    delete表名&#x27;</span>;行键&quot;,列族列,&#123;TIMESTEMP= &gt;&#x27;235652&#x27;&#125;</span><br><span class="line">    清空表: truncate &#x27;表名&#x27;</span><br><span class="line">    数据获取: get &#x27;表名&#x27;;行键’</span><br><span class="line">    get &#x27;表名&#x27;行键&quot;;列族列</span><br><span class="line">    <span class="keyword">get</span> <span class="string">&#x27;表名&#x27;</span>，<span class="string">&#x27;行键&quot;;列族列,&#123;VERSIONS=&gt;3&#125;</span></span><br><span class="line"><span class="string">    数据扫描: scan &#x27;</span>表名<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    scan &#x27;</span>表名&quot;&#x27;;行键&#x27;;列族列,VERSIONS= &gt;3&#125;</span><br><span class="line"></span><br><span class="line">snapshot:快照操作--&gt; 针对表创建快照，记录当前指定表的数据信息</span><br><span class="line">    创建快照: snapshot &#x27;表名&quot;，<span class="string">&#x27;快照名称&#x27;</span></span><br><span class="line">    还原快照: resotre_ snapshot <span class="string">&#x27;快照名&#x27;</span></span><br><span class="line">    克隆快照: clone_ snapshot ‘快照名;新表名<span class="string">&#x27; ---&gt;把快照中的表内容还原到一-张新表上</span></span><br><span class="line"><span class="string">    删除快照: delete snapshot &#x27;</span>快照名<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>


<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><pre><code>数据仓库，查询分析
</code></pre>
<h2 id="Hadoop生态圈"><a href="#Hadoop生态圈" class="headerlink" title="Hadoop生态圈"></a>Hadoop生态圈</h2><ul>
<li>HDFS存储、 HBase存储提供实时读写功能</li>
<li>MapReduce并行计算、Yarn资源管理和任务调度</li>
<li>ZooKeeper协助分布式应用管理服务</li>
<li>Hive底层使用的是MapReduce做计算，MapReduce的使用对编程人员要求比较高</li>
<li>可以执行SQL类的查询分析计算</li>
</ul>
<h2 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_19.png" alt="Hive数据模型"></p>
<ul>
<li><p>分区:根据字段值进行划分(指定分区字段,分区字段值相同的记录就存放在一一个分区中)<br>分区在物理上是一个文件夹<br>分区下还可以再有分区和桶<br>在创建表的时候可以指定分区字段<br>分区数量是不固定的</p>
</li>
<li><p>桶:根据值的哈希值进行求余放到对应的桶中<br>桶在物理.上是一-个文件<br>在创建表的时候可以指定有几个桶</p>
</li>
<li><p>表类型:托管表(内部表)、外部表、临时表<br>托管表(internal) :元数据和数据信息都是Hive在管理<br><code>删除时，元数据和数据都会被删除\</code><br>外部表(external) :元数据由Hive管理,但是数据可以提供给其他组件共享<br><code>删除时，只删除元数据，数据信息依旧保留\</code><br>临时表(temporary) :只在当前会话中生效，当会话结束表就会被自动删除</p>
</li>
</ul>
<h2 id="Hive数据仓库分层-逻辑分层"><a href="#Hive数据仓库分层-逻辑分层" class="headerlink" title="Hive数据仓库分层(逻辑分层)"></a>Hive数据仓库分层<code>(逻辑分层)</code></h2><ul>
<li>ODS (原数据层，操作数据层) :从数据源获取到的数据</li>
<li>DWD (数据明细层) :根据ODS做数据清洗得到的结果</li>
<li>DWS (数据服务层) :根据DWD进行汇总分析计算</li>
<li>ADS (应用服务层) :根据上层应用的业务需求将DWS数据再一次处理分析得到业务 需要的数据</li>
</ul>
<h2 id="Hive的分层处理的优势"><a href="#Hive的分层处理的优势" class="headerlink" title="Hive的分层处理的优势"></a>Hive的分层处理的优势</h2><ul>
<li>复杂问题简单化:将复杂问题分成多个流程，每个层面执行一-一个流程内容</li>
<li>减少重复开发:不要每次提供给上次应用数据时都要对数据进行清洗汇总操作</li>
<li>隔离原始数据:减少到原数据的依赖，避免因为原数据的原因，导致后续操作无法执行</li>
</ul>
<h2 id="Hive-SQL的使用"><a href="#Hive-SQL的使用" class="headerlink" title="Hive SQL的使用"></a>Hive SQL的使用</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">DDL:数据定义语言</span><br><span class="line">    创建表: <span class="keyword">create</span> <span class="keyword">table</span> <span class="string">&#x27;表名(字段类型,字段2类类型... .);</span></span><br><span class="line"><span class="string">    create external table表名&#x27;</span>(字段类型,字段<span class="number">2</span>类型....</span><br><span class="line">    <span class="keyword">create</span> temporary <span class="keyword">table</span> <span class="string">&#x27;表名&#x27;</span>(字段类型,字段<span class="number">2</span>类型... .</span><br><span class="line">    修改表: <span class="keyword">alter</span> <span class="keyword">table</span>表名<span class="string">&#x27; rename to &#x27;</span>新表名;</span><br><span class="line">    <span class="keyword">alter</span> <span class="keyword">table</span> <span class="string">&#x27;表名&#x27;</span> addcolumns (字段类型);</span><br><span class="line">    删除表: <span class="keyword">drop</span> <span class="keyword">table</span> <span class="string">&#x27;表名&#x27;</span>;</span><br><span class="line">    查询数据库中的所有表: <span class="keyword">show</span> tables;</span><br><span class="line">    查看表信息: <span class="keyword">describe</span> <span class="keyword">table</span> <span class="string">&#x27;表名&#x27;</span>;</span><br><span class="line">    </span><br><span class="line">DML:数据管理语言</span><br><span class="line">    添加数据:从文件中添加到表中</span><br><span class="line">    load data inpath HDFS路径<span class="keyword">into</span> <span class="keyword">table</span>表名</span><br><span class="line">    load data <span class="keyword">local</span> inpath Linux路径<span class="keyword">into</span> <span class="keyword">table</span>表名</span><br><span class="line">    load data <span class="keyword">local</span> inpath Linux路径overwrite <span class="keyword">into</span> <span class="keyword">table</span>表</span><br><span class="line">    </span><br><span class="line">    从一个表添加到另<span class="operator">-</span>一个表中</span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> 表名 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 原表 <span class="keyword">where</span>条件;</span><br><span class="line">    <span class="keyword">from</span> 原表 <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> 表名 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">where</span> 条件</span><br><span class="line">    <span class="keyword">from</span> 原表 <span class="keyword">insert</span> overwrite <span class="keyword">table</span> 表名 <span class="keyword">select</span> 字段 <span class="keyword">where</span> 条件</span><br><span class="line">    从表中导出到文件中</span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> directory HDFS路径 <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span>表</span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">local</span> directory Linux 路径<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表</span><br><span class="line">    export <span class="keyword">table</span> 表 <span class="keyword">to</span> HDFS路径</span><br><span class="line">    </span><br><span class="line">DQL:数据查询语言</span><br><span class="line">    标准查询: <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span>表名</span><br><span class="line">    分组: <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 <span class="keyword">group</span> <span class="keyword">by</span>字段</span><br><span class="line">    排序: <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 <span class="keyword">order</span> <span class="keyword">by</span>字段<span class="keyword">desc</span></span><br><span class="line">    多表联合查询: <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表 a <span class="keyword">join</span> 表b  <span class="keyword">on</span> a.id<span class="operator">=</span> b.id)</span><br><span class="line">    </span><br><span class="line">创建表时的特殊操作</span><br><span class="line">    分区: partitioned (字段类型)</span><br><span class="line">    指定列分隔符: <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;分隔符&#x27;</span></span><br><span class="line">    指定外部表的存储路径: location 路径</span><br><span class="line">    指定外部表的存储类型: stored <span class="keyword">as</span> textfile</span><br><span class="line">    指定字段加密: <span class="type">ROW</span> FORMAT SERDE</span><br><span class="line">    <span class="string">&#x27;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&#x27;</span> <span class="keyword">WITH</span> SERDEPROPERTIES(</span><br><span class="line">    <span class="string">&#x27;column.encode.columns&#x27;</span><span class="operator">=</span><span class="string">&#x27;字段1,字段</span></span><br><span class="line"><span class="string">    2&#x27;</span>column.encode.classname<span class="string">&#x27; =&#x27;</span>org apache.hadoop.hive.serde2.AESRewriter);</span><br></pre></td></tr></table></figure>

<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="Spark特点"><a href="#Spark特点" class="headerlink" title="Spark特点"></a>Spark特点</h2><pre><code>轻快灵巧Spark的处理能力是MapReduce的30倍，处理能力不容易受到任务量增加的影响
</code></pre>
<p>轻:底层代码只有3万行，使用的函数式编程语言scala<br>快:处理速度快<br>灵:提供很多不同层面的处理功能<br>巧:巧妙的应用Hadoop平台</p>
<h2 id="RDD-分布式数据集、可分区的"><a href="#RDD-分布式数据集、可分区的" class="headerlink" title="RDD:分布式数据集、可分区的"></a>RDD:分布式数据集、可分区的</h2><ul>
<li>具有血统机制(RDD由父RDD执行操作之后产生)</li>
<li>如果子RDD丢失，RDD故障，重新执行父RDD就可以重新得到的子RDD</li>
<li>RDD默认存储在内存中，如果内存不足的时候，发生溢写</li>
<li>Spark节点会分配60%的内存用于做缓存，40%执行内存</li>
</ul>
<h2 id="依赖类型"><a href="#依赖类型" class="headerlink" title="依赖类型"></a>依赖类型</h2><pre><code>宽依赖、窄依赖
</code></pre>
<ul>
<li>窄依赖:父RDD的每个分区都只会被<code>一个</code>子RDD的分区所依赖</li>
<li>宽依赖:父RDD的每个分区可能会被<code>多个子RDD的分区所依赖</code></li>
</ul>
<h2 id="Stage划分"><a href="#Stage划分" class="headerlink" title="Stage划分"></a>Stage划分</h2><pre><code>遇到窄依赖就加入，宽依赖就断开，剩余的所有RDD被放在一个Stage中
</code></pre>
<h2 id="RDD操作类型"><a href="#RDD操作类型" class="headerlink" title="RDD操作类型"></a>RDD操作类型</h2><ul>
<li><p>创建操作:创建RDD用于接收数据结果</p>
</li>
<li><p>原始RDD:读取数据源获得的RDD (readFile(path))</p>
</li>
<li><p>转换得来:通过父RDD执行操作后得到的子RDD</p>
</li>
<li><p>控制操作:持久化RDD,可以持久化到内存或磁盘中,默认存在内存</p>
</li>
<li><p>转换操作:可对RDD执行的处理操作，转换操作是懒惰的，转换操作并不是立马执行，遇到行动操作才执行</p>
</li>
<li><p>行动操作:实际调用Spark执行(存储文件,数据输出等)</p>
</li>
<li><p>transformation算子在整个程序中 -&gt;声明转换操作,实际并没有执行</p>
</li>
<li><p>action算子时， 会从第一-个操作开始执行</p>
</li>
<li><p>DataFrame:属于一个DataSet实例， 不可变的弹性分布式数据集，存储数据时不止存储数据内容,存储数据对应结构信息及类型</p>
</li>
<li><p>DataSet:以对象的形式存储数据集，DataFrame&#x3D; DataSet[Row]</p>
</li>
</ul>
<h2 id="RDD、DataFrame、-DataSet数据集的联系"><a href="#RDD、DataFrame、-DataSet数据集的联系" class="headerlink" title="RDD、DataFrame、 DataSet数据集的联系"></a>RDD、DataFrame、 DataSet数据集的联系</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_20.png" alt="数据集的联系"></p>
<h2 id="Spark体系架构"><a href="#Spark体系架构" class="headerlink" title="Spark体系架构"></a>Spark体系架构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_21.png" alt="Spark体系架构"></p>
<ul>
<li>集群部署形式: <br>Standalone: spark自 己管理资源调度<br>Spark On Yarn:使用yarn做资源管理调度 <br>Mesos: AMR实验室开发的资源管理器，最适用于Spark的资源管理器</li>
<li>Spark Core:处理核心</li>
<li>Spark SQL:处理结构化数据，使用Hive元数据</li>
<li>Spark Streaming:实时流处理(实际微批处理) , 能够低延迟的计算反馈结果</li>
<li>MLLib:机器学习,根据历史数据进行建模，根据模型和提供的数据进行数据预测</li>
<li>GraphX:图计算,主要用于关系统计,关系查询</li>
<li>SparkR: R语言库,提供R语言接口，可以使用R语言操作Spark</li>
<li>Structured Streaming:流处理，将数据存入-个无边界表(新数据不断添加，旧数据不断移除)使用增量的方式获取表数据内容进行执行</li>
</ul>
<h1 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h1><pre><code>分布式流处理组件
</code></pre>
<h2 id="关键特性-实时响应，延迟性低"><a href="#关键特性-实时响应，延迟性低" class="headerlink" title="关键特性:实时响应，延迟性低"></a>关键特性:实时响应，延迟性低</h2><ul>
<li>数据不存储先执行(离线处理先存储数据然后再执行)</li>
<li>连续查询(程序运行后就不终止,除非系统故障导致的终止或者手动停止)</li>
<li>事件驱动:传入的数据信息触动任务处理</li>
</ul>
<h2 id="Streaming系统架构"><a href="#Streaming系统架构" class="headerlink" title="Streaming系统架构"></a>Streaming系统架构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_22.png" alt="Streaming系统架构"></p>
<ul>
<li>Client:客户端接口</li>
<li>Nimbus (主节点) :接收客户端的请求，管理Supervisor从节点，管理任务分配，编写任务书</li>
<li>Supervisor (从节点) :实行任务，管理worker</li>
<li>Worker (进程) :程序执行</li>
<li>Executor (线程) :每个Executor中默认执行一 一个Task</li>
<li>Task (任务) : Task分别对应每一 个Spout&#x2F;Bolt组件的执行 </li>
<li>ZooKeeper:监控Nimbus主节点的状态，如果主节点故障切换备用节点<br>监控Supervisor从节点状态，如果从节点故障,通知Nimbus迁移任务，启动自动恢复<br>接收Nimbus任务书，将每个从节点的任务存放在每个Supervisor自己对应的目录中</li>
</ul>
<h2 id="Streaming任务架构"><a href="#Streaming任务架构" class="headerlink" title="Streaming任务架构"></a>Streaming任务架构</h2><ul>
<li>Topology:拓扑结构,封装任务执行流程</li>
<li>Spout:发送数据源的组件,接收第三方数据收集I具提供的数据发送到数据流</li>
<li>每个应用只有一个spout</li>
<li>Bolt:从数据流中获取数据,执行数据处理，如果当前bolt不是最后-个执行程序将结果放回数据流一个应用中可以有多个bolt</li>
<li>Tuple:数据流中的数据格式，组件之间数据传输的格式，元组中包含两个参数(id, stream)</li>
</ul>
<h2 id="Streaming执行任务"><a href="#Streaming执行任务" class="headerlink" title="Streaming执行任务"></a>Streaming执行任务</h2><ol>
<li>用户通过Client提交应用到Nimbus中</li>
<li>Nimbus接收到应用后，根据应用情况及当前集群的从节点情况编写任务书</li>
<li>将任务书.上传到ZooKeeper中</li>
<li>ZooKeeper接收到任务书后根据每个节点将对应的任务存放在节点对应的目录下</li>
<li>Supervisor周期性监测自己在ZooKeeper中的目录有没有新任务</li>
<li>Supervisor发现新任务，根据任务书内容从Nimbus中下载任务所需要的jar包</li>
<li>Supervisor执行任务,反馈执行状态给Nimbus .</li>
<li>Nimbus将任务状态反馈给Client</li>
</ol>
<h2 id="根据任务架构执行"><a href="#根据任务架构执行" class="headerlink" title="根据任务架构执行"></a>根据任务架构执行</h2><ol>
<li>获取拓扑结构</li>
<li>根据拓扑结构分别找到每一流程的处理单元</li>
<li>按照路程执行处理单元</li>
</ol>
<h2 id="消息传递语义"><a href="#消息传递语义" class="headerlink" title="消息传递语义"></a>消息传递语义</h2><ul>
<li>最多一次:数据发送只发送一次, 可靠性最低，吞吐量最大<br>  缺点:可能存在数据丢失的情况<br>  优点:数据一定不会被重复执行</li>
<li>最少一次:数据可能会发送多次，可靠性高，吞吐量较小<br>  优点:数据不会丢失<br>  缺点:数据可能会被重复执行</li>
<li>仅有一次(精准一次) :数据就发送一-次, 并且保证发送成功，可靠性高，吞吐量最低<br>  优点:数据不会丢失，且数据不被重复处理<br>  缺点:消耗的资源和时间较多</li>
</ul>
<h2 id="Ack机制-消息传输最少一次"><a href="#Ack机制-消息传输最少一次" class="headerlink" title="Ack机制(消息传输最少一次)"></a>Ack机制(消息传输最少一次)</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_23.png" alt="Ack机制"></p>
<h1 id="Fink"><a href="#Fink" class="headerlink" title="Fink"></a>Fink</h1><pre><code>分布式实时计算引擎(流处理引擎)
</code></pre>
<h2 id="Flink-VS-Spark-Streaming"><a href="#Flink-VS-Spark-Streaming" class="headerlink" title="Flink VS Spark Streaming"></a>Flink VS Spark Streaming</h2><ul>
<li>Flink可以做流处理(侧重)也可以做批处理，底层引擎属于流处理引擎</li>
<li>通过流处理引擎模拟批处理形式实现的批处理</li>
<li>Spark可以做流处理也可以做批处理(侧重点)，底层弓|擎属于批处理引擎</li>
<li>通过批处理引擎,模拟流处理实现的流处理功能</li>
</ul>
<h2 id="Flink的关键特性"><a href="#Flink的关键特性" class="headerlink" title="Flink的关键特性"></a>Flink的关键特性</h2><pre><code>状态、时间、窗口、检查点
</code></pre>
<h2 id="Flink系统架构"><a href="#Flink系统架构" class="headerlink" title="Flink系统架构"></a>Flink系统架构</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_24.png" alt="Flink系统架构"></p>
<ul>
<li>部署形式: Local (单机版部署)<br>  Cluster (Standalone: Flink集群自己管理资源调度<br>  Yarn:借助Yarn组件帮助管理协调资源和任务)<br>  Clound (云部署)</li>
<li>Flink核心模块: Runtime (不管是流处理还是批处理都是在Runtime中执行)</li>
<li>接口层: DataStream (流处理)和DataSet (批处理)</li>
<li>Table API &amp; SQL:处理结构化数据<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Table</span> API:将操作应用封装成方法</span><br><span class="line">    <span class="keyword">select</span>(&quot;t_ demo &quot;).<span class="keyword">where</span>(&quot;条件&quot;)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">SQL</span>:基于<span class="keyword">Table</span> API使用，</span><br><span class="line">    sqlQuery(&quot;select * from t_ demo where条件&quot;)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="有界流和无界流"><a href="#有界流和无界流" class="headerlink" title="有界流和无界流"></a>有界流和无界流</h2><ul>
<li>有界流:知道开始，知道结束，使用批处理处理有界流数据.</li>
<li>无界流:知道开始，不知道结束，使用流处理接口进行数据处理</li>
</ul>
<h2 id="DataStream-用于存储数据的数据集，只能执行流处理操作"><a href="#DataStream-用于存储数据的数据集，只能执行流处理操作" class="headerlink" title="DataStream:用于存储数据的数据集，只能执行流处理操作"></a>DataStream:用于存储数据的数据集，只能执行流处理操作</h2><ul>
<li>基于流处理运行环境获取到的数据</li>
</ul>
<h2 id="DataSet-用来接收数据的数据集，只能执行批处理操作"><a href="#DataSet-用来接收数据的数据集，只能执行批处理操作" class="headerlink" title="DataSet:用来接收数据的数据集，只能执行批处理操作"></a>DataSet:用来接收数据的数据集，只能执行批处理操作</h2><ul>
<li>基于批处理运行环境获取到的数据</li>
</ul>
<p><code>并不能在一个应用中同时接收流处理和批处理接口，以此实现流处理和批处理的共用</code></p>
<h2 id="Flink运行流程"><a href="#Flink运行流程" class="headerlink" title="Flink运行流程"></a>Flink运行流程</h2><p><img src="/2022/04/20/%E5%8D%8E%E4%B8%BAHCIA/img_25.png" alt="Flink运行流程"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="Fink的架构和原理"><a href="#Fink的架构和原理" class="headerlink" title="Fink的架构和原理"></a>Fink的架构和原理</h2><h2 id="Fink的Time和Window"><a href="#Fink的Time和Window" class="headerlink" title="Fink的Time和Window"></a>Fink的Time和Window</h2><p>Fink窗口类型:</p>
<ul>
<li>滑动窗口: 窗口移动方式是平移,设定参数时需要设定窗口大小,滑动距离.窗口大小固定,可能会出现数据源重复和数据丢失的情况</li>
<li>滚动窗口: 窗口移动方式滚动,滚动距离就是窗口大小,设定窗口时只需要设定窗口大小.窗口大小固定,不会出现数据重复或者数据丢失的情况,会出现空窗口的情况</li>
<li>会话窗口: 由会话启动的窗口,设定过期时间,窗口代销不固定,运行时不会有丢失的数据,不会出现空窗口</li>
<li>时间窗口: 以时间为条件设定的窗口,<code>分别可以再分为滑动或滚动</code></li>
<li>数量窗口: 由会话启动的窗口,设定过期时间,<code>分别可以再分为滑动或滚动</code></li>
</ul>
<p>Fink的时间类型:</p>
<ul>
<li>时间类型: 事件发生的时间 </li>
<li>时间类型: 时间达到处理系统的时间</li>
<li>处理时间(默认): 时间被处理的时间</li>
<li>时间乱序问题: 事件被处理的顺序不是时间产生顺序</li>
<li>时间乱序原因: 数据受到数据传输影响</li>
</ul>
<h2 id="Fink的Watermark"><a href="#Fink的Watermark" class="headerlink" title="Fink的Watermark"></a>Fink的Watermark</h2><p>Watermark(水位线&#x2F;水印): 解决数据乱序问题</p>
<ul>
<li>设定水位线时间,当水位线设定的时间时间也达到系统时,就会触发窗口执行</li>
<li>可设置水位线延迟,可允许窗口延迟触发</li>
</ul>
<p>对于延迟数据的处理方式:</p>
<ul>
<li>丢弃(默认): 当窗口已经被触发过,该窗口的数据达到也会被丢弃,不会被执行</li>
<li>可允许延迟: 设定可允许延迟时间,窗口已经被执行,但是输在可允许延迟时间达到,重新重发窗口的执行<br><code>allowedLateness</code>(可延迟时间)</li>
<li>收集后做统一处理: 把所有的延迟数据收集起来,在程序最后做统一处理<br>Output <h2 id="Fink的容错"><a href="#Fink的容错" class="headerlink" title="Fink的容错"></a>Fink的容错</h2></li>
</ul>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.JPG" alt="chenci 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.JPG" alt="chenci 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/HCIA/" rel="tag"># HCIA</a>
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/04/18/msf%E5%90%8E%E6%B8%97%E9%80%8F%E4%BD%BF%E7%94%A8/" rel="prev" title="msf后渗透使用">
                  <i class="fa fa-chevron-left"></i> msf后渗透使用
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chenci</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  





</body>
</html>
